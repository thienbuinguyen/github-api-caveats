{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "from random import sample, shuffle, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "caveat_files_dir = './output/java_12_spec_caveat_sentences_revised/'\n",
    "caveats_dict = {}\n",
    "\n",
    "files = glob.glob(caveat_files_dir + '*.json')\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        arr = json.load(f)\n",
    "        for caveat in arr:\n",
    "            caveats_dict[caveat['id']] = caveat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 4712\n",
      "Number of class level caveat sentences: 9964\n",
      "Number of api level caveat sentences: 37578\n",
      "Number of misc sentences: 37865\n",
      "Number of deprecated caveats: 1522\n",
      "{'constructor': 4172, 'method': 33827, 'field': 6403}\n"
     ]
    }
   ],
   "source": [
    "# Print statistics about the caveats found using keywords\n",
    "\n",
    "caveat_type_count = {} # map caveat types to their counts\n",
    "print(\"Number of classes: {}\".format(len(files)))\n",
    "\n",
    "class_level_sentences = 0\n",
    "caveat_sentences = 0\n",
    "caveat_misc_sentences = 0\n",
    "deprecated = 0\n",
    "num_caveats = len(caveats_dict)\n",
    "\n",
    "for key in caveats_dict:\n",
    "    caveat = caveats_dict[key]\n",
    "    \n",
    "    if \"class_caveat_sentences\" in caveat:\n",
    "        class_level_sentences += len(caveat[\"class_caveat_sentences\"])\n",
    "    else:\n",
    "        caveat_sentences += len(caveat['sentences'])\n",
    "        for misc in caveat['caveat_misc']:\n",
    "            if 'parameters' in misc:\n",
    "                for obj in misc['parameters']:\n",
    "                    caveat_misc_sentences += len(obj['sentences'])\n",
    "            elif 'exceptions' in misc:\n",
    "                for obj in misc['exceptions']:\n",
    "                    caveat_misc_sentences += len(obj['sentences'])\n",
    "            else:\n",
    "                 caveat_misc_sentences += len(misc['list'])\n",
    "\n",
    "    if caveat['deprecated']:\n",
    "        deprecated += 1\n",
    "    \n",
    "    if 'type' in caveat:        \n",
    "        if not caveat['type'] in caveat_type_count:\n",
    "            caveat_type_count[caveat['type']] = 1\n",
    "        else:\n",
    "            caveat_type_count[caveat['type']] += 1\n",
    "\n",
    "print(\"Number of class level caveat sentences: {}\".format(class_level_sentences))\n",
    "print(\"Number of api level caveat sentences: {}\".format(caveat_sentences))  \n",
    "print(\"Number of misc sentences: {}\".format(caveat_misc_sentences))\n",
    "print(\"Number of deprecated caveats: {}\".format(deprecated))\n",
    "print(caveat_type_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_doccano_import_file(file, arr):\n",
    "    \"\"\" Write the dict objects within an input array to a json file in doccano import format \"\"\"\n",
    "    with open(file, 'w+') as f:\n",
    "        for obj in arr:\n",
    "            f.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class sentences: 9333\n",
      "Number of method sentences: 31403\n",
      "Number of field sentences: 1726\n",
      "Number of constructor sentences: 2224\n",
      "-----------------------------------\n",
      "Number of exception sentences: 29841\n",
      "Number of return sentences: 10800\n",
      "Number of parameter sentences: 10875\n"
     ]
    }
   ],
   "source": [
    "caveat_sentences_array = []\n",
    "sentence_id_to_caveat_id = {}\n",
    " \n",
    "def normalize_sentence(sentence):\n",
    "    \n",
    "\n",
    "for key in caveats_dict:\n",
    "    caveat = caveats_dict[key]\n",
    "    \n",
    "    if caveat['deprecated']:\n",
    "        continue\n",
    " \n",
    "    if 'class_level_caveat_sentences' in caveat:\n",
    "        for sentence in caveat['class_level_caveat_sentences']:\n",
    "            if len(sentence) > 0:\n",
    "                sentence_id_to_caveat_id[len(caveat_sentences_array)] = caveat['id']\n",
    "                caveat_sentences_array.append({\n",
    "                    'text': sentence, \n",
    "                     'id': len(caveat_sentences_array),\n",
    "                     'type': 'class'\n",
    "                })\n",
    "    else:\n",
    "        for sentence in caveat['caveat_sentences']:\n",
    "            if len(sentence) > 0:\n",
    "                sentence_id_to_caveat_id[len(caveat_sentences_array)] = caveat['id']\n",
    "                caveat_sentences_array.append({\n",
    "                    'text': sentence, \n",
    "                     'id': len(caveat_sentences_array),\n",
    "                     'type': caveat['type']\n",
    "                })\n",
    "\n",
    "            # add sentences for throws, returns etc...\n",
    "            if caveat['type'] in ['method', 'constructor']:\n",
    "                for misc in caveat['caveat_misc']:\n",
    "                    for misc_sentence in misc['text_list']:\n",
    "                        if len(misc_sentence) > 0:\n",
    "                            sentence_id_to_caveat_id[len(caveat_sentences_array)] = caveat['id']\n",
    "                            caveat_sentences_array.append({\n",
    "                                'text': misc_sentence, \n",
    "                                 'id': len(caveat_sentences_array),\n",
    "                                'type': 'misc@' + misc['name']\n",
    "                            })\n",
    "\n",
    "class_sentences = [o for o in caveat_sentences_array if o['type'] == 'class' and len(o['text']) <= 400]\n",
    "method_sentences = [o for o in caveat_sentences_array if o['type'] == 'method' and len(o['text']) <= 400]\n",
    "field_sentences = [o for o in caveat_sentences_array if o['type'] == 'field' and len(o['text']) <= 400]\n",
    "constructor_sentences = [o for o in caveat_sentences_array if o['type'] == 'constructor' and len(o['text']) <= 400]\n",
    "misc_sentences = [o for o in caveat_sentences_array if 'misc' in o['type'] and len(o['text']) <= 400]\n",
    "        \n",
    "print(\"Number of class sentences: {}\".format(len(class_sentences)))\n",
    "print(\"Number of method sentences: {}\".format(len(method_sentences)))\n",
    "print(\"Number of field sentences: {}\".format(len(field_sentences)))\n",
    "print(\"Number of constructor sentences: {}\".format(len(constructor_sentences)))\n",
    "\n",
    "exception_sentences = [o for o in misc_sentences if 'Throws:' == o['type'].split('@')[1]]\n",
    "return_sentences = [o for o in misc_sentences if 'Returns:' == o['type'].split('@')[1]]\n",
    "parameter_sentences = [o for o in misc_sentences if 'Parameters:' == o['type'].split('@')[1]]\n",
    "\n",
    "print('-----------------------------------')\n",
    "print('Number of exception sentences: {}'.format(len(exception_sentences)))\n",
    "print('Number of return sentences: {}'.format(len(return_sentences)))\n",
    "print('Number of parameter sentences: {}'.format(len(parameter_sentences)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique class sentences: 8558\n",
      "Number of unique method sentences: 21321\n",
      "Number of unique field sentences: 1471\n",
      "Number of unique constructor sentences: 1439\n",
      "-----------------------------------\n",
      "Number of unique exception sentences: 5961\n",
      "Number of unique return sentences: 4043\n",
      "Number of unique parameter sentences: 2732\n"
     ]
    }
   ],
   "source": [
    "def get_unique_text_objs(arr):\n",
    "    seen_text = set()\n",
    "    filtered = []\n",
    "    for obj in arr:\n",
    "        if not obj['text'] in seen_text:\n",
    "            filtered.append(obj)\n",
    "            seen_text.add(obj['text'])\n",
    "        \n",
    "    return filtered\n",
    "\n",
    "seed(42)\n",
    "\n",
    "filtered_class_sentences = get_unique_text_objs(class_sentences)\n",
    "filtered_method_sentences = get_unique_text_objs(method_sentences)\n",
    "filtered_field_sentences = get_unique_text_objs(field_sentences)\n",
    "filtered_constructor_sentences = get_unique_text_objs(constructor_sentences)\n",
    "# misc sentences\n",
    "filtered_exception_sentences = get_unique_text_objs(exception_sentences)\n",
    "filtered_return_sentences = get_unique_text_objs(return_sentences)\n",
    "filtered_parameter_sentences = get_unique_text_objs(parameter_sentences)\n",
    "\n",
    "print(\"Number of unique class sentences: {}\".format(len(filtered_class_sentences)))\n",
    "print(\"Number of unique method sentences: {}\".format(len(filtered_method_sentences)))\n",
    "print(\"Number of unique field sentences: {}\".format(len(filtered_field_sentences)))\n",
    "print(\"Number of unique constructor sentences: {}\".format(len(filtered_constructor_sentences)))\n",
    "print('-----------------------------------')\n",
    "print('Number of unique exception sentences: {}'.format(len(filtered_exception_sentences)))\n",
    "print('Number of unique return sentences: {}'.format(len(filtered_return_sentences)))\n",
    "print('Number of unique parameter sentences: {}'.format(len(filtered_parameter_sentences)))\n",
    "\n",
    "# # sample 384 of each list for 95% confidence interval with 5% error margin\n",
    "# filtered_class_sentences = sample(filtered_class_sentences, 384)\n",
    "# filtered_method_sentences = sample(filtered_method_sentences, 384)\n",
    "# filtered_field_sentences = sample(filtered_field_sentences, 384)\n",
    "# filtered_constructor_sentences = sample(filtered_constructor_sentences, 384)\n",
    "# # misc sentences\n",
    "# filtered_exception_sentences = sample(filtered_exception_sentences, 384)\n",
    "# filtered_return_sentences = sample(filtered_return_sentences, 384)\n",
    "# filtered_parameter_sentences = sample(filtered_parameter_sentences, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to annotate to different files\n",
    "# write_to_doccano_import_file('./output/method_sentences_doccano.jsonl', filtered_method_sentences)\n",
    "# write_to_doccano_import_file('./output/constructor_sentences_doccano.jsonl', filtered_constructor_sentences)\n",
    "write_to_doccano_import_file('./output/exception_sentences_doccano.jsonl', filtered_exception_sentences)\n",
    "# write_to_doccano_import_file('./output/return_sentences_doccano.jsonl', filtered_return_sentences)\n",
    "write_to_doccano_import_file('./output/parameter_sentences_doccano.jsonl', filtered_parameter_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify labelled data from doccano\n",
    "def get_labelled_doccano_data(labelled_file, metadata):\n",
    "    with open(labelled_file) as f, open(metadata) as metadata_f:\n",
    "        id_to_label = {}\n",
    "        arr = json.load(metadata_f)\n",
    "        for e in arr:\n",
    "            id_to_label[e['id']] = e['text']\n",
    "\n",
    "        data = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            obj = json.loads(line)\n",
    "            obj['labels'] = [id_to_label[i['label']] for i in obj['annotations']]\n",
    "            obj.pop('annotations', None)\n",
    "            obj.pop('meta', None)\n",
    "            obj.pop('annotation_approver', None)\n",
    "            data.append(obj)\n",
    "    \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labelled_data(file):\n",
    "    with open(file) as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def get_label_counts(arr):\n",
    "    counts = {}\n",
    "    \n",
    "    for e in arr:\n",
    "        for label in e['labels']:\n",
    "            if not label in counts:\n",
    "                counts[label] = 1\n",
    "            else:\n",
    "                counts[label] += 1\n",
    "                \n",
    "    return counts\n",
    "\n",
    "def write_labelled_doccano_data(doccano_file, metadata_file, output_file):\n",
    "    with open(output_file, 'w+') as f:\n",
    "        json.dump(get_labelled_doccano_data(doccano_file, metadata_file), output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Exception': 21, 'Guard': 37, 'Other': 322, 'Temporal': 6}\n",
      "{'Explicit': 78, 'Implicit': 301, 'Temporal': 5}\n",
      "{'Other': 367, 'Temporal': 4, 'Exception': 9, 'Guard': 5}\n",
      "{'Other': 293, 'Temporal': 2, 'Guard': 87, 'Exception': 2}\n",
      "{'Other': 382, 'Temporal': 1}\n"
     ]
    }
   ],
   "source": [
    "# load all labelled sentences\n",
    "constructor_sents = get_labelled_data('./labelled_constructor_sentences.json')\n",
    "exception_sents = get_labelled_data('./labelled_exception_sentences.json')\n",
    "method_sents = get_labelled_data('./labelled_method_sentences.json')\n",
    "parameter_sents = get_labelled_data('./labelled_parameter_sentences.json')\n",
    "return_sents = get_labelled_data('./labelled_return_sentences.json')\n",
    "\n",
    "print(get_label_counts(constructor_sents))\n",
    "print(get_label_counts(exception_sents))\n",
    "print(get_label_counts(method_sents))\n",
    "print(get_label_counts(parameter_sents))\n",
    "print(get_label_counts(return_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ROOT                          \n",
      "                 |                             \n",
      "                 S                            \n",
      "       __________|__________________________   \n",
      "      |                     VP              | \n",
      "      |                 ____|___            |  \n",
      "      |                |        PP          | \n",
      "      |                |     ___|_____      |  \n",
      "      |                |    |         S     | \n",
      "      |                |    |         |     |  \n",
      "      NP               |    |         VP    | \n",
      "  ____|__________      |    |         |     |  \n",
      " DT   JJ    JJ   NN   VBZ   IN       VBG    . \n",
      " |    |     |    |     |    |         |     |  \n",
      "The quick brown fox  sucks  at     jumping  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# POS and dependency parsing\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "parser = CoreNLPParser(url='http://localhost:9010')\n",
    "next(parser.raw_parse('The quick brown fox sucks at jumping.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "CLASS_0 - if defaultSelection is null\n"
     ]
    }
   ],
   "source": [
    "regex_strs = []\n",
    "with open('./heuristic_regex_exception.txt') as f:\n",
    "    for line in f:\n",
    "        if line == '\\n' or line[0] == '#':\n",
    "            continue\n",
    "        else:\n",
    "            regex_strs.append(line.strip())\n",
    "            \n",
    "important = []\n",
    "for obj in exception_sents:\n",
    "    for s in regex_strs:\n",
    "        m = re.search(s, obj['text'], re.IGNORECASE)\n",
    "        if m:\n",
    "            important.append(obj['id'])\n",
    "            break\n",
    "\n",
    "print(len(important))\n",
    "for obj in exception_sents:\n",
    "    if 'Explicit' in obj['labels'] and obj['id'] not in important:\n",
    "        print(obj['text'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND\n"
     ]
    }
   ],
   "source": [
    "regex = r\"example\"\n",
    "import re\n",
    "if re.search(regex, \"This is an Example sentence\", re.IGNORECASE):\n",
    "    print(\"FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'CLASS_1 - if PARAMETER_0 is METHOD_0 and METHOD_3 returns false', 'id': 222, 'type': 'misc@Throws:'}\n"
     ]
    }
   ],
   "source": [
    "print(filtered_exception_sentences[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'setLookAndFeel', 'type': 'method', 'signature': 'public static void setLookAndFeel(LookAndFeel newLookAndFeel) throws UnsupportedLookAndFeelException', 'deprecated': False, 'caveat_sentences': ['If the current look and feel is METHOD_0 uninitialize is invoked on it.', 'If PARAMETER_0 is METHOD_0, METHOD_1 is invoked on it followed by METHOD_2.', 'If the PARAMETER_0 is null, the look and feel defaults are set to null.', 'A value of null can be used to set the look and feel to null.', 'As the CLASS_0 is required for most of Swing to function, setting the CLASS_0 to null is strongly discouraged.'], 'caveat_misc': [{'name': 'Throws:', 'text_list': ['CLASS_1 - if PARAMETER_0 is METHOD_0 and METHOD_3 returns false']}], 'id': 48468, 'mappings': {'parameters': ['newLookAndFeel'], 'fields': [], 'methods': ['non-null', 'initialize', 'getDefaults', 'newLookAndFeel.isSupportedLookAndFeel()', 'getLookAndFeel()'], 'primitives': [], 'classes': ['LookAndFeel', 'UnsupportedLookAndFeelException']}}\n"
     ]
    }
   ],
   "source": [
    "for key in caveats_dict:\n",
    "    caveat = caveats_dict[key]\n",
    "    \n",
    "    if caveat['id'] == sentence_id_to_caveat_id[222]:\n",
    "        print(caveat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([]) == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if \n"
     ]
    }
   ],
   "source": [
    "test = 'true if this list contains no elements'\n",
    "keywords = ['insecure', 'susceptible', 'error', 'exception', 'null', 'susceptible',\n",
    "         'unavailable', 'not thread safe','illegal', 'inappropriate', 'deprecate', 'better to', 'best to',\n",
    "         'recommended', 'less desirable','discourage', 'instead of', 'rather than','otherwise',\n",
    "         'do not', 'note that', 'notably', 'caution', 'under the condition', 'whether ', 'if ',\n",
    "          'when ', 'assume that ', 'before', 'after', 'must', 'should', 'have to', 'need to',\n",
    "           'be not', 'never', 'none', 'only', 'always']\n",
    "\n",
    "\n",
    "sentences = nltk.sent_tokenize(test)\n",
    "\n",
    "for sentence in sentences:\n",
    "    for keyword in keywords:\n",
    "        matches = re.search(keyword, sentence, re.IGNORECASE)\n",
    "        if matches:\n",
    "            print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
