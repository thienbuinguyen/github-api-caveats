{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "\n",
    "parser = CoreNLPParser(url='http://localhost:9010', tagtype='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the non-dreprecated java doc caveat sentences of methods (parameters or exception level)\n",
    "caveat_files_dir = './output/java_12_spec_caveat_sentences_revised/'\n",
    "method_caveats = []\n",
    "parameter_caveats = []\n",
    "exception_caveats = []\n",
    "\n",
    "files = sorted(glob.glob(caveat_files_dir + '*.json'))\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        arr = ujson.load(f)\n",
    "        full_class_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        simple_class_name = full_class_name.split('.')[-1]\n",
    "        \n",
    "        for caveat in arr:\n",
    "            if not caveat['deprecated'] and 'name' in caveat:\n",
    "                \n",
    "                # collect the name of parameters\n",
    "                collected = False\n",
    "                parameters = []\n",
    "                for misc_obj in caveat['caveat_misc']:\n",
    "                    if misc_obj['name'] == 'Parameters:':\n",
    "                        for obj in misc_obj['list']:\n",
    "                            parameters.append(obj['parameter'])\n",
    "                        collected = True\n",
    "                        break\n",
    "                        \n",
    "                for sentence in caveat['sentences']:\n",
    "                    method_caveats.append({\n",
    "                                    'obj': '',\n",
    "                                    'simple_class_name': simple_class_name,\n",
    "                                    'full_class_name': full_class_name,\n",
    "                                    'api': caveat['name'],\n",
    "                                    'signature': caveat['signature'],\n",
    "                                    'sentence': sentence,\n",
    "                                    'parameters': parameters,\n",
    "                                    'type': 'method'\n",
    "                                })\n",
    "\n",
    "                if collected:\n",
    "                    # add all parameter and exception level sentences\n",
    "                    for misc_obj in caveat['caveat_misc']:\n",
    "                        if misc_obj['name'] in ['Parameters:', 'Throws:']:\n",
    "                            for obj in misc_obj['list']:\n",
    "                                for misc_sentence in obj['sentences']:\n",
    "                                    if misc_obj['name'] == 'Parameters:':\n",
    "                                        parameter_caveats.append({\n",
    "                                            'obj': obj['parameter'],\n",
    "                                            'simple_class_name': simple_class_name,\n",
    "                                            'full_class_name': full_class_name,\n",
    "                                            'api': caveat['name'],\n",
    "                                            'signature': caveat['signature'],\n",
    "                                            'sentence': misc_sentence,\n",
    "                                            'parameters': parameters,\n",
    "                                            'type': 'parameter'\n",
    "                                        })\n",
    "                                    else:\n",
    "                                        exception_caveats.append({\n",
    "                                            'obj': obj['exception'],\n",
    "                                            'simple_class_name': simple_class_name,\n",
    "                                            'full_class_name': full_class_name,\n",
    "                                            'api': caveat['name'],\n",
    "                                            'signature': caveat['signature'],\n",
    "                                            'sentence': misc_sentence,\n",
    "                                            'parameters': parameters,\n",
    "                                            'type': 'exception'\n",
    "                                        })\n",
    "                                        \n",
    "method_caveat_df = pd.DataFrame(method_caveats)\n",
    "parameter_caveat_df = pd.DataFrame(parameter_caveats)\n",
    "exception_caveat_df = pd.DataFrame(exception_caveats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_pattern(sentence, patterns, lowercase):\n",
    "    if lowercase:\n",
    "        sentence = sentence.lower()\n",
    "    if sentence:\n",
    "        for pattern in patterns:\n",
    "            matches = re.search(pattern, sentence)\n",
    "            if matches:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Regex patterns for filtering\n",
    "exception_not_null_patterns = [\n",
    "#     '(be|equal|equals|is|are) null',\n",
    "#     'be (equal|equivalent) to null',\n",
    "#     'non-null',\n",
    "     'null'\n",
    "]\n",
    "\n",
    "exception_range_limitation_patterns = [\n",
    "    r'<|>|=',\n",
    "    r'equal|equal to|equivalent to|illegal value| is (nan|infinite|empty)',\n",
    "    r'\\b(less|smaller|greater|larger)\\b',\n",
    "    r'\\b(range|negative|positive|non-negative|non-positive)\\b'\n",
    "]\n",
    "\n",
    "exception_type_restriction_patterns = [\n",
    "    r'is( not)? an? [A-Z][a-z]+([A-Za-z_0-9\\.]*)*',\n",
    "    r'instance of|return type'\n",
    "]\n",
    "\n",
    "parameter_not_null_patterns = [\n",
    "    r'not( be)? null',\n",
    "    r'non-null',\n",
    "]\n",
    "\n",
    "parameter_range_limitation_patterns = [\n",
    "     r'<|>|=',\n",
    "     r'(less|smaller|greater|larger) than',\n",
    "     r'negative|positive|non-negative|non-positive'\n",
    "]\n",
    "\n",
    "def exception_not_null_filter(sentence):\n",
    "    return filter_by_pattern(sentence, exception_not_null_patterns, lowercase=True)\n",
    "\n",
    "def exception_range_limitation_filter(sentence):\n",
    "    return filter_by_pattern(sentence, exception_range_limitation_patterns, lowercase=True)\n",
    "\n",
    "def exception_type_restriction_filter(sentence):\n",
    "    return filter_by_pattern(sentence, exception_type_restriction_patterns, lowercase=False)\n",
    "\n",
    "def parameter_not_null_filter(sentence):\n",
    "    return filter_by_pattern(sentence, parameter_not_null_patterns, lowercase=True)\n",
    "\n",
    "def parameter_range_limitation_filter(sentence):\n",
    "    return filter_by_pattern(sentence, parameter_range_limitation_patterns, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception caveat sentences\n",
      "{'Ambiguous': 256, 'NullnessNotAllowed': 92, 'RangeLimitation': 27, 'TypeRestriction': 9, 'Dependent': 9}\n",
      "Filter results for not_null\n",
      "Correct: 92\n",
      "Retrieved: 92\n",
      "\n",
      "Filter results for range\n",
      "Correct: 27\n",
      "Retrieved: 35\n",
      "\n",
      "Filter results for type\n",
      "Correct: 9\n",
      "Retrieved: 10\n",
      "\n",
      "Parameter caveat sentences\n",
      "{'NullnessNotAllowed': 36, 'Ambiguous': 222, 'ExpectedValue': 3, 'RangeLimitation': 3}\n",
      "Filter results for not_null\n",
      "Correct: 36\n",
      "Retrieved: 37\n",
      "\n",
      "Filter results for range\n",
      "Correct: 3\n",
      "Retrieved: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exception_filters = {\n",
    "    'not_null': (exception_not_null_filter, 'NullnessNotAllowed'),\n",
    "    'range': (exception_range_limitation_filter, 'RangeLimitation'),\n",
    "    'type': (exception_type_restriction_filter, 'TypeRestriction')\n",
    "}\n",
    "\n",
    "parameter_filters = {\n",
    "    'not_null': (parameter_not_null_filter, 'NullnessNotAllowed'),\n",
    "    'range': (parameter_range_limitation_filter, 'RangeLimitation')\n",
    "}\n",
    "\n",
    "def analyse_labelled_results(file, filters):\n",
    "    with open(file) as f:\n",
    "        counts = {}\n",
    "        c = 0\n",
    "        for line in f:\n",
    "            obj = ujson.loads(line)\n",
    "\n",
    "            if obj['labels']:\n",
    "                c += 1\n",
    "                if c > 384:\n",
    "                    break\n",
    "\n",
    "                for label in obj['labels']:\n",
    "                    if not label in counts:\n",
    "                        counts[label] = 1\n",
    "                    else:\n",
    "                        counts[label] += 1\n",
    "        print(counts)\n",
    "\n",
    "        for key in filters:\n",
    "            print('Filter results for {}'.format(key))\n",
    "            correct, retrieved = 0, 0\n",
    "            c = 0\n",
    "            f.seek(0)\n",
    "            for line in f:\n",
    "                obj = ujson.loads(line)\n",
    "\n",
    "                if obj['labels']:\n",
    "                    c += 1\n",
    "                    if c > 384:\n",
    "                        break\n",
    "\n",
    "                    if filters[key][0](obj['text']):\n",
    "                        retrieved += 1\n",
    "                        if filters[key][1] in obj['labels']:\n",
    "                            correct += 1\n",
    "#                         else:\n",
    "#                             print(obj)\n",
    "#                     elif filters[key][1] in obj['labels']:\n",
    "#                         print('MISS')\n",
    "#                         print(obj)\n",
    "\n",
    "            print('Correct: {}'.format(correct))\n",
    "            print('Retrieved: {}\\n'.format(retrieved))\n",
    "  \n",
    "# Test filtering rules\n",
    "print('Exception caveat sentences')\n",
    "analyse_labelled_results('./labelled_data/labelled_exception_full.jsonl', exception_filters)\n",
    "print('Parameter caveat sentences')\n",
    "analyse_labelled_results('./labelled_data/labelled_parameter_full.jsonl', parameter_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered results: 3844\n",
      "Unique results: 1447\n",
      "\n",
      "Filtered results: 1202\n",
      "Unique results: 495\n",
      "\n",
      "Filtered results: 1946\n",
      "Unique results: 834\n",
      "\n",
      "Filtered results: 335\n",
      "Unique results: 193\n",
      "\n",
      "Filtered results: 208\n",
      "Unique results: 149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method_caveat_df = pd.DataFrame(method_caveats)\n",
    "parameter_caveat_df = pd.DataFrame(parameter_caveats)\n",
    "exception_caveat_df = pd.DataFrame(exception_caveats)\n",
    "\n",
    "def get_unique_filtered_df(df, filter_func):\n",
    "    filtered_df = df[df['sentence'].apply(filter_func)]\n",
    "    unique_df = filtered_df.drop_duplicates('sentence').sample(frac=1)\n",
    "    print('Filtered results: {}'.format(len(filtered_df.index)))\n",
    "    print('Unique results: {}\\n'.format(len(unique_df.index)))\n",
    "    return unique_df\n",
    "\n",
    "# Not null exception\n",
    "not_null_exception_df = get_unique_filtered_df(exception_caveat_df, exception_not_null_filter)\n",
    "\n",
    "# Not null paramater\n",
    "not_null_parameter_df = get_unique_filtered_df(parameter_caveat_df, parameter_not_null_filter)\n",
    "\n",
    "# Range limitation exception\n",
    "range_limit_exception_df = get_unique_filtered_df(exception_caveat_df, exception_range_limitation_filter)\n",
    "\n",
    "# Range limitation parameter\n",
    "range_limit_parameter_df = get_unique_filtered_df(parameter_caveat_df, parameter_range_limitation_filter)\n",
    "\n",
    "# Type restriction exception\n",
    "type_restrict_exception_df = get_unique_filtered_df(exception_caveat_df, exception_type_restriction_filter)\n",
    "\n",
    "def create_annotation_file(df, size, out_path, include_obj=False):\n",
    "    with open(out_path, 'w+') as out_f:\n",
    "        c = 0\n",
    "        for i in df.index:\n",
    "            c += 1\n",
    "            if c == 1:\n",
    "                out_f.write('-----------------------------')\n",
    "            \n",
    "            if c > size:\n",
    "                break\n",
    "            \n",
    "            out_f.write(str(i) + '\\n')\n",
    "            out_f.write(df.loc[i, 'signature'] + '\\n')\n",
    "            if include_obj:\n",
    "                out_f.write(df.loc[i,'obj'] + '\\n')\n",
    "            out_f.write(df.loc[i, 'sentence'] + '\\n\\n')\n",
    "            out_f.write('-----------------------------')\n",
    "            \n",
    "\n",
    "# create_annotation_file(type_restrict_exception_df, 100, './output/labelled_caveat_rules/type_restrict_exception.txt')\n",
    "# create_annotation_file(not_null_exception_df, 100, './output/labelled_caveat_rules/not_null_exception.txt')\n",
    "# create_annotation_file(not_null_parameter_df, 100, './output/labelled_caveat_rules/not_null_parameter.txt', True)\n",
    "# create_annotation_file(range_limit_exception_df, 100, './output/labelled_caveat_rules/range_limit_exception.txt')\n",
    "# create_annotation_file(range_limit_parameter_df, 100, './output/labelled_caveat_rules/range_limit_parameter.txt', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "90\n",
      "72\n",
      "49\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "def read_labelled_rule_results(path, parser, rule_start=3, offset=4):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        indices = [re.sub(\"[^0-9]\", \"\", line) for line in lines[::offset]]\n",
    "        rules = [line.strip() for line in lines[rule_start::offset]]\n",
    "        \n",
    "        if len(indices) > len(rules):\n",
    "            indices = indices[:len(rules)]\n",
    "        \n",
    "        results = {}\n",
    "        for i, val in enumerate(indices):\n",
    "            results[val] = parser(rules[i])\n",
    "            \n",
    "        return results\n",
    "    \n",
    "def or_parser(expression):\n",
    "    if expression == '':\n",
    "        return None\n",
    "    return expression.split('||')\n",
    "\n",
    "def type_parser(expression):\n",
    "    if expression == '':\n",
    "        return None\n",
    "    \n",
    "    expressions = expression.split(' & ')\n",
    "    results = []\n",
    "    for exp in expressions:\n",
    "        components = exp.split(' -> ')\n",
    "        types = components[1].split('||')\n",
    "        negated = components[0][0] == '!'\n",
    "        \n",
    "        obj = components[0]\n",
    "        if components[0][0] == '!':\n",
    "            obj = components[0][1:]\n",
    "        results.append({'obj': obj, 'types': types, 'negated':negated})\n",
    "    \n",
    "    return results\n",
    "        \n",
    "not_null_exception_results = read_labelled_rule_results('./labelled_data/not_null_exception.txt', or_parser)\n",
    "print(len([x for x in not_null_exception_results if not_null_exception_results[x]]))\n",
    "\n",
    "not_null_parameter_results = read_labelled_rule_results('./labelled_data/not_null_parameter.txt', or_parser, 4, 5)\n",
    "print(len([x for x in not_null_parameter_results if not_null_parameter_results[x]]))\n",
    "\n",
    "range_limit_exception_results = read_labelled_rule_results('./labelled_data/range_limit_exception.txt', or_parser)\n",
    "print(len([x for x in range_limit_exception_results if range_limit_exception_results[x]]))\n",
    "\n",
    "range_limit_parameter_results = read_labelled_rule_results('./labelled_data/range_limit_parameter.txt', or_parser, 4, 5)\n",
    "print(len([x for x in range_limit_parameter_results if range_limit_parameter_results[x]]))\n",
    "\n",
    "type_restrict_exception_results = read_labelled_rule_results('./labelled_data/type_restrict_exception.txt', type_parser)\n",
    "print(len([x for x in type_restrict_exception_results if type_restrict_exception_results[x]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_rules(api_caveat_obj):\n",
    "    skip_patterns = [\n",
    "        r'subclass|at the specified',\n",
    "        r'any .*element of .* is( not)? an?',\n",
    "        r'and ([a-z]\\w+) is( not)? an? ((?:[A-Z]\\w+(?:, )?)+)(?:or(?: a)? ([A-Z]\\w+))?',\n",
    "        r' ([a-z]\\w+) is( not)? an? ((?:[A-Z]\\w+(?:, )?)+)(?:or(?: a)? ([A-Z]\\w+))? and'\n",
    "    ]\n",
    "    for pattern in skip_patterns:\n",
    "        if re.search(pattern, api_caveat_obj['sentence']):\n",
    "            return\n",
    "    matches = re.search(r' ([a-z]\\w+) is( not)? a Class that implements interface ([A-Z]\\w+)', api_caveat_obj['sentence'])\n",
    "    if matches:\n",
    "        results = []\n",
    "        negated = matches.group(1) != None\n",
    "        results.append({'obj': matches.group(0), 'types': [matches.group(2)], 'negated': negated})\n",
    "    \n",
    "    else:\n",
    "        matches = re.findall(r' ([a-z]\\w+) is( not)? an? ((?:[A-Z]\\w+,? ?)+)(?:or ([A-Z]\\w+))?', api_caveat_obj['sentence'])\n",
    "        if matches:\n",
    "            results = []\n",
    "            for match in matches:\n",
    "                if match[0] in api_caveat_obj['parameters']:\n",
    "                    types = [e.strip() for e in match[2].split(', ') if len(e) > 0]\n",
    "                    if match[3]:\n",
    "                        types.append(match[3])\n",
    "                    # only look at class names (first char is uppercase)\n",
    "                    types = [t for t in types if t[0].isupper()]\n",
    "                    if len(types) == 0:\n",
    "                        continue\n",
    "\n",
    "                    negated = match[1] == '' # not we check the reversed negation\n",
    "                    results.append({'obj': match[0], 'types': types, 'negated': negated})\n",
    "\n",
    "            return results\n",
    "    \n",
    "def is_not_null_parameter_caveat(api_caveat_obj):\n",
    "    sentence = api_caveat_obj['sentence'].lower()\n",
    "    \n",
    "    # skip conditional\n",
    "    if 'if ' in sentence:\n",
    "        return False\n",
    "    \n",
    "    patterns = [\n",
    "        r'not( be)? null',\n",
    "        r'non-null'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, sentence):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_not_null_exception_rules(api_caveat_obj):\n",
    "    # skip additional condition patterns\n",
    "    skip_patterns = [\n",
    "        r' and .* is null',\n",
    "        r' is null and',\n",
    "        r' any of the arguments',\n",
    "        r' contains null element'\n",
    "    ]\n",
    "    \n",
    "    types = []\n",
    "    \n",
    "    for pattern in skip_patterns:\n",
    "        if re.search(pattern, api_caveat_obj['sentence']):\n",
    "            return types\n",
    "    \n",
    "    # assume the caveat is about single parameters\n",
    "    if len(api_caveat_obj['parameters']) == 1 and re.search(' null', api_caveat_obj['sentence']):\n",
    "        return api_caveat_obj['parameters']\n",
    "    \n",
    "    match = re.search(r'([Ii]f|[Ww]hen) (.*) null', api_caveat_obj['sentence'])\n",
    "    if match:\n",
    "        tokens = re.sub(', ', ' ', match.group(2)).split()\n",
    "        types = [t for t in tokens if t in api_caveat_obj['parameters']]\n",
    "    return set(types)\n",
    "\n",
    "def get_range_limitation_exception_rules(api_caveat_obj):   \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_sentence(sentence, parameters):      \n",
    "    # variable substitutions\n",
    "    variable_subs = [\n",
    "        r'\\W(-?[0-9]+(?:,[0-9]+)*(?:(?:\\.[0-9]+)?[a-z]*))', # specific numeric value\n",
    "        r'\\W(\"[^\"]+\")', # simple string\n",
    "        r'([A-Za-z_]+[A-Za-z_0-9]*\\.[A-Za-z_][A-Za-z_0-9]*\\(\\))', # class method\n",
    "        r'((^(java\\.|javax\\.|org\\.))?([A-Za-z_]\\w*\\.)+\\w+)', # member value of object/Class\n",
    "        r'(([A-Za-z_][A-Za-z_0-9])*\\(\\))' # standalone methods (empty param list only)\n",
    "    ]\n",
    "        \n",
    "    # list of expression substitutions for logical phrases, note ordering is used\n",
    "    worded_subs = [\n",
    "        (r'(not? less than)', '>='),\n",
    "        (r'(not? greater than)', '<='),\n",
    "        (r'(greater than or equal to)', '>='),\n",
    "        (r'(less than or equal to)', '<='),\n",
    "        (r'(less than)', '<'),\n",
    "        (r'(greater than)', '>'),\n",
    "        (r'((is|are)? negative)', '< 0'),\n",
    "        (r'((is|are)? positive)', '< 0'),\n",
    "        (r'(not equal to)', '!='),\n",
    "        (r'( is not )', '!='),\n",
    "        (r'(equal to)', '==')\n",
    "    ]\n",
    "    \n",
    "    # normalise all equality phrases\n",
    "    for t in worded_subs:\n",
    "        match = re.search(t[0], sentence)\n",
    "        while match:\n",
    "            sentence = re.sub(match.group(1), t[1], sentence)\n",
    "            match = re.search(t[0], sentence)\n",
    "            \n",
    "        variable_prefix = 'VAR_'\n",
    "    variable_counter = 'a'\n",
    "    variable_dict = {}\n",
    "    \n",
    "    # normalise all API call parameters\n",
    "    for parameter in parameters:\n",
    "        print(parameter)\n",
    "        key = variable_prefix + str(variable_counter)\n",
    "        variable_dict[key] = parameter\n",
    "        sentence = re.sub(r'\\b'+parameter+r'\\b', key, sentence)\n",
    "        variable_counter = chr(ord(variable_counter) + 1)\n",
    "    \n",
    "    # normalise all variables that match predefined expression patterns\n",
    "    for pattern in variable_subs:\n",
    "        match = re.search(pattern, sentence)\n",
    "        while match:\n",
    "            key = variable_prefix + str(variable_counter)\n",
    "            variable_dict[key] = match.group(1)\n",
    "            next_pattern = re.escape(match.group(1))\n",
    "            sentence = re.sub(next_pattern, key, sentence)\n",
    "            variable_counter = chr(ord(variable_counter) + 1)\n",
    "            \n",
    "            match = re.search(pattern, sentence)\n",
    "\n",
    "    # locate enumerations (lists of items)\n",
    "    list_dict = {}\n",
    "    list_counter = 0\n",
    "    list_prefix = 'LIST_'\n",
    "    pattern = '\\W((\\s*[A-Za-z0-9_@]+\\s*)(,\\s*[A-Za-z0-9_@]+\\s*)+,?\\s*or\\s*[A-Za-z0-9_@]+)\\W'\n",
    "    match = re.search(pattern, sentence)\n",
    "\n",
    "    while match:\n",
    "        key = list_prefix + str(list_counter)\n",
    "        sentence = re.sub(match.group(1), key, sentence)\n",
    "        list_dict[key] = match.group(1)\n",
    "        \n",
    "        match = re.search(pattern, sentence)\n",
    "        list_counter += 1\n",
    "    \n",
    "    expressions_dict = {}\n",
    "    expression_prefix = 'EXPR_'\n",
    "    expression_counter = 0\n",
    "    start_index = 0\n",
    "    bracket_counter = 0\n",
    "    for i, c in enumerate(sentence):\n",
    "        if c == '(': \n",
    "            bracket_counter += 1\n",
    "        elif c == ')':\n",
    "            bracket_counter -= 1\n",
    "            # TODO: malformed sentences\n",
    "            if bracket_counter == 0:\n",
    "                substr = sentence[start_index:i]\n",
    "                start_index = i + 1\n",
    "                \n",
    "                if re.search(r'-|\\+|\\*|/|<|<=|>|>=|==|!=|&&|\\|\\||\\.\\.', substr):\n",
    "                    escaped = re.escape(substr)\n",
    "                    key = expression_prefix + str(expression_counter)\n",
    "                    expressions_dict[key] = substr\n",
    "                    sentence = re.sub(escaped, key, sentence)\n",
    "                    expression_counter += 1\n",
    "    \n",
    "    # remove spaces around operators if adjacent to valid variables/digits\n",
    "    match = re.search(r'([A-Za-z_\\(\\)][A-Za-z0-9_\\.\\(\\)]*)\\s+(-|\\+|\\*|/|<|<=|>|>=|==|!=|&&|\\|\\||&|\\.\\.)\\s+([A-Za-z_\\(\\)][A-Za-z0-9_\\.\\(\\)]+)', sentence)\n",
    "    while match and not match in seen_expressions:\n",
    "        print(match.groups())\n",
    "        sub = match.group(2)\n",
    "        if not (match.group(1).startswith('VAR_') or match.group(1).startswith('LIST_')):\n",
    "            sub = ' ' + sub\n",
    "        if not (match.group(3).startswith('VAR_') or match.group(3).startswith('LIST_')):\n",
    "            sub = sub + ' '\n",
    "         \n",
    "        sub = match.group(1) + sub + match.group(3)\n",
    "        escaped = re.escape(match.group(0))\n",
    "        print(sentence)\n",
    "        sentence = re.sub(escaped, sub, sentence)\n",
    "        seen_expressions.add(match)\n",
    "        \n",
    "        match = re.search(r'([A-Za-z_\\(\\)][A-Za-z0-9_\\.\\(\\)]*)\\s+(-|\\+|\\*|/|<|<=|>|>=|==|!=|&&|\\|\\||&|\\.\\.)\\s+([A-Za-z_\\(\\)][A-Za-z0-9_\\.\\(\\)]+)', sentence)\n",
    "#         if len(seen_expressions) > 2:\n",
    "#             break\n",
    "    return sentence, variable_dict, list_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if iv is null or EXPR_1)\n",
      "{'EXPR_0': '(wordSize / 8)', 'EXPR_1': '(iv.length - offset < 2 * EXPR_0'}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"if iv is null or (iv.length - offset < 2 * (wordSize / 8))\"\n",
    "expressions_dict = {}\n",
    "expression_prefix = 'EXPR_'\n",
    "expression_counter = 0\n",
    "start_index = 0\n",
    "bracket_counter = 0\n",
    "old_len = 0\n",
    "first = True\n",
    "\n",
    "while first or len(expressions_dict) != old_len:\n",
    "    first = False\n",
    "    old_len = len(expressions_dict)\n",
    "    for i, c in enumerate(sentence):\n",
    "        if c == '(': \n",
    "            bracket_counter += 1\n",
    "            start_index = i\n",
    "        elif c == ')':\n",
    "            bracket_counter -= 1\n",
    "            # TODO: malformed sentences\n",
    "            if bracket_counter == 0:\n",
    "                substr = sentence[start_index:i]\n",
    "                start_index = i + 1\n",
    "\n",
    "                if re.search(r'-|\\+|\\*|/|<|<=|>|>=|==|!=|&&|\\|\\||\\.\\.', substr):\n",
    "                    escaped = re.escape(substr)\n",
    "                    key = expression_prefix + str(expression_counter)\n",
    "                    expressions_dict[key] = substr\n",
    "                    sentence = re.sub(escaped, key, sentence)\n",
    "                    expression_counter += 1\n",
    "    \n",
    "print(sentence)\n",
    "print(expressions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version\n",
      "rounds\n",
      "wordSize\n",
      "offset\n",
      "if iv is null or (VAR_g - VAR_d < VAR_e * (VAR_c / VAR_f))\n",
      "('(VAR_g', '-', 'VAR_d')\n",
      "if iv is null or (VAR_g - VAR_d < VAR_e * (VAR_c / VAR_f))\n",
      "('VAR_d', '<', 'VAR_e')\n",
      "if iv is null or (VAR_g -VAR_d < VAR_e * (VAR_c / VAR_f))\n",
      "('VAR_e', '*', '(VAR_c')\n",
      "if iv is null or (VAR_g -VAR_d<VAR_e * (VAR_c / VAR_f))\n",
      "('(VAR_c', '/', 'VAR_f))')\n",
      "if iv is null or (VAR_g -VAR_d<VAR_e* (VAR_c / VAR_f))\n",
      "('if iv is null or (VAR_g -VAR_d<VAR_e* (VAR_c /VAR_f))', {'VAR_a': 'version', 'VAR_b': 'rounds', 'VAR_c': 'wordSize', 'VAR_d': 'offset', 'VAR_e': '2', 'VAR_f': '8', 'VAR_g': 'iv.length'}, {})\n"
     ]
    }
   ],
   "source": [
    "test = \"if iv is null or (iv.length - offset < 2 * (wordSize / 8))\"\n",
    "print(normalise_sentence(test, ['version', 'rounds', 'wordSize', 'offset']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'EXPR_0': ('iv.length - offset', 'iv.length', 'offset'), 'EXPR_1': ('2 * (wordSize', '2', '(wordSize'), 'EXPR_2': ('0 < EXPR', '0', 'EXPR', '')}, 'if iv is null or (EXPR_EXPR_2_1 / 8))')\n",
      "[[('if', 'IN'), ('iv', 'NN'), ('is', 'VBZ'), ('null', 'JJ')], [('iv.length', 'JJ'), ('-', ':'), ('offset', 'VBN'), ('2', 'CD'), ('wordSize', 'NN'), ('8', 'CD')]]\n"
     ]
    }
   ],
   "source": [
    "k = 10935\n",
    "# sent = 'a != b and b < 1'\n",
    "# expressions_dict = {}\n",
    "# normalize_sentence_expressions(sent)\n",
    "get_range_limitation_exception_rules(range_limit_exception_df.loc[k].to_dict())\n",
    "# print(range_limit_exception_results[str(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type', 'source', 'connectionId'}\n",
      "['type', 'source', 'connectionId']\n"
     ]
    }
   ],
   "source": [
    "k = 12403\n",
    "print(get_not_null_exception_rules(not_null_exception_df.loc[k].to_dict()))\n",
    "print(not_null_exception_results[str(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'obj': 'src', 'types': ['IndexColorModel'], 'negated': True}]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_type_rules(type_restrict_exception_df.loc[12403].to_dict()))\n",
    "print(type_restrict_exception_results['1762'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16414\n",
      "16423\n",
      "7928\n",
      "5174\n",
      "8009\n",
      "16388\n",
      "16411\n",
      "7990\n",
      "10139\n",
      "14367\n",
      "12594\n",
      "12676\n",
      "16398\n",
      "12607\n",
      "MISFIND\n",
      "1762\n",
      "retrieved:15, correct:14, total: 33\n"
     ]
    }
   ],
   "source": [
    "# evaluate type rules generation via regex\n",
    "retrieved, correct, total = 0, 0, 0\n",
    "for key in type_restrict_exception_results:\n",
    "    index = int(key)\n",
    "    caveat_obj = type_restrict_exception_df.loc[index].to_dict()\n",
    "    \n",
    "    rules = get_type_rules(caveat_obj)\n",
    "    if rules:\n",
    "        retrieved += 1\n",
    "        \n",
    "        if not type_restrict_exception_results[key]:\n",
    "            print('MISFIND')\n",
    "            print(index)\n",
    "            continue\n",
    "        \n",
    "        is_correct = True\n",
    "        if not type_restrict_exception_results[key]:\n",
    "            is_correct = False\n",
    "        \n",
    "        has_match = False\n",
    "        for rule in rules:\n",
    "            match = [e for e in type_restrict_exception_results[key] if e['obj'] == rule['obj']]\n",
    "            if len(match) > 0 and match[0]['types'] == rule['types'] and match[0]['negated'] == rule['negated']:\n",
    "                has_match = True\n",
    "                break\n",
    "        \n",
    "        if is_correct and has_match:\n",
    "            print(index)\n",
    "            correct += 1\n",
    "            \n",
    "    if type_restrict_exception_results[key]:\n",
    "        total += 1\n",
    "print('retrieved:{}, correct:{}, total: {}'.format(retrieved, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4227\n",
      "retrieved:91, correct:90, total: 90\n"
     ]
    }
   ],
   "source": [
    "# evaluate not null rules (parameter sentences) generation via regex\n",
    "retrieved, correct, total = 0, 0, 0\n",
    "for key in not_null_parameter_results:\n",
    "    index = int(key)\n",
    "    caveat_obj = not_null_parameter_df.loc[index].to_dict()\n",
    "    \n",
    "    rule = is_not_null_parameter_caveat(caveat_obj)\n",
    "    if rule:\n",
    "        retrieved += 1\n",
    "        \n",
    "        if not not_null_parameter_results[key]:\n",
    "            print(index)\n",
    "            continue\n",
    "        \n",
    "        correct += 1\n",
    "            \n",
    "    if not_null_parameter_results[key]:\n",
    "        if not rule:\n",
    "            print(index)\n",
    "        total += 1\n",
    "print('retrieved:{}, correct:{}, total: {}'.format(retrieved, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3078\n",
      "8702\n",
      "12013\n",
      "3994\n",
      "8651\n",
      "12091\n",
      "12587\n",
      "12519\n",
      "3112\n",
      "14946\n",
      "949\n",
      "8146\n",
      "15643\n",
      "3364\n",
      "12088\n",
      "retrieved:81, correct:75, total: 84\n"
     ]
    }
   ],
   "source": [
    "# evaluate not null rules (exception sentences) generation via regex\n",
    "retrieved, correct, total = 0, 0, 0\n",
    "\n",
    "for key in not_null_exception_results:\n",
    "    index = int(key)\n",
    "    caveat_obj = not_null_exception_df.loc[index].to_dict()\n",
    "    \n",
    "    rules = get_not_null_exception_rules(caveat_obj)\n",
    "    if rules:\n",
    "        retrieved += 1\n",
    "        \n",
    "        if not not_null_exception_results[key] or set(not_null_exception_results[key]) != set(rules):\n",
    "            print(index)\n",
    "            continue\n",
    "        \n",
    "        correct += 1\n",
    "            \n",
    "    if not_null_exception_results[key]:\n",
    "        if not rules:\n",
    "            print(index)\n",
    "        total += 1\n",
    "print('retrieved:{}, correct:{}, total: {}'.format(retrieved, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ROOT                                                                             \n",
      "      |                                                                                \n",
      "     SBAR                                                                             \n",
      "  ____|________                                                                        \n",
      " |             S                                                                      \n",
      " |     ________|___________                                                            \n",
      " |    |                    VP                                                         \n",
      " |    |     _______________|____________________                                       \n",
      " |    |    |                                    NP                                    \n",
      " |    |    |                        ____________|_______________________               \n",
      " |    |    |                       NP                                   |             \n",
      " |    |    |            ___________|____________________                |              \n",
      " |    |    |           |       |       NP           |   |               |             \n",
      " |    |    |           |       |    ___|___         |   |               |              \n",
      " |    |    |           |       |   |      SBAR      |   |               |             \n",
      " |    |    |           |       |   |       |        |   |               |              \n",
      " |    |    |           |       |   |       S        |   |               X             \n",
      " |    |    |           |       |   |       |        |   |        _______|_______       \n",
      " |    |    |           NP      |   |       VP       |   |       X               |     \n",
      " |    |    |        ___|___    |   |    ___|____    |   |    ___|___            |      \n",
      " |    NP   |       NP      NP  |   NP  |        NP  |   NP  X       NP          NP    \n",
      " |    |    |    ___|___    |   |   |   |        |   |   |   |    ___|___     ___|___   \n",
      " IN   NN  VBZ  NN      NN  CD  CC NNP SYM       CD  CC NNP SYM  CD      NN  NN      CD\n",
      " |    |    |   |       |   |   |   |   |        |   |   |   |   |       |   |       |  \n",
      " if value  is VAR      _   0   or VAR  _        1  and VAR  _   3      VAR  _       2 \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def preprocess(sentence):\n",
    "    if sentence[-1] == '.':\n",
    "        sentence = sentence[:-1]\n",
    "    \n",
    "    sentence = re.sub(r'[^\\w\\. -]', '', sentence)\n",
    "    # remove brackets surrounding text\n",
    "    matches = re.findall(r' ([^)])', sentence)\n",
    "    for match in matches:\n",
    "        sentence = re.sub(match, match[0], sentence)\n",
    "    return sentence\n",
    "\n",
    "def tokenize(sentence):    \n",
    "    return sentence.split()\n",
    "\n",
    "test = 'if value is < @VAR_0 or > @VAR_1, and @VAR_3 > @VAR_2'\n",
    "processed_text = tokenize(preprocess(test))\n",
    "# print(parser.tag(processed_text))\n",
    "print(next(next(parser.parse_sents([processed_text]))).pretty_print())\n",
    "# next(parser.raw_parse('if number is null or not an instance of Number')).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
