{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "\n",
    "parser = CoreNLPParser(url='http://localhost:9010', tagtype='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the non-dreprecated java doc caveat sentences of methods (parameters or exception level)\n",
    "caveat_files_dir = './output/java_12_spec_caveat_sentences_revised/'\n",
    "method_caveats = []\n",
    "parameter_caveats = []\n",
    "exception_caveats = []\n",
    "\n",
    "files = sorted(glob.glob(caveat_files_dir + '*.json'))\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        arr = ujson.load(f)\n",
    "        full_class_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        simple_class_name = full_class_name.split('.')[-1]\n",
    "        \n",
    "        for caveat in arr:\n",
    "            if not caveat['deprecated'] and 'name' in caveat:\n",
    "                \n",
    "                # collect the name of parameters\n",
    "                collected = False\n",
    "                parameters = []\n",
    "                for misc_obj in caveat['caveat_misc']:\n",
    "                    if misc_obj['name'] == 'Parameters:':\n",
    "                        for obj in misc_obj['list']:\n",
    "                            parameters.append(obj['parameter'])\n",
    "                        collected = True\n",
    "                        break\n",
    "                        \n",
    "                for sentence in caveat['sentences']:\n",
    "                    method_caveats.append({\n",
    "                                    'obj': '',\n",
    "                                    'simple_class_name': simple_class_name,\n",
    "                                    'full_class_name': full_class_name,\n",
    "                                    'api': caveat['name'],\n",
    "                                    'signature': caveat['signature'],\n",
    "                                    'sentence': sentence,\n",
    "                                    'parameters': parameters,\n",
    "                                    'type': 'method'\n",
    "                                })\n",
    "\n",
    "                if collected:\n",
    "                    # add all parameter and exception level sentences\n",
    "                    for misc_obj in caveat['caveat_misc']:\n",
    "                        if misc_obj['name'] in ['Parameters:', 'Throws:']:\n",
    "                            for obj in misc_obj['list']:\n",
    "                                for misc_sentence in obj['sentences']:\n",
    "                                    if misc_obj['name'] == 'Parameters:':\n",
    "                                        parameter_caveats.append({\n",
    "                                            'obj': obj['parameter'],\n",
    "                                            'simple_class_name': simple_class_name,\n",
    "                                            'full_class_name': full_class_name,\n",
    "                                            'api': caveat['name'],\n",
    "                                            'signature': caveat['signature'],\n",
    "                                            'sentence': misc_sentence,\n",
    "                                            'parameters': parameters,\n",
    "                                            'type': 'parameter'\n",
    "                                        })\n",
    "                                    else:\n",
    "                                        exception_caveats.append({\n",
    "                                            'obj': obj['exception'],\n",
    "                                            'simple_class_name': simple_class_name,\n",
    "                                            'full_class_name': full_class_name,\n",
    "                                            'api': caveat['name'],\n",
    "                                            'signature': caveat['signature'],\n",
    "                                            'sentence': misc_sentence,\n",
    "                                            'parameters': parameters,\n",
    "                                            'type': 'exception'\n",
    "                                        })\n",
    "                                        \n",
    "method_caveat_df = pd.DataFrame(method_caveats)\n",
    "parameter_caveat_df = pd.DataFrame(parameter_caveats)\n",
    "exception_caveat_df = pd.DataFrame(exception_caveats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_pattern(sentence, patterns, lowercase):\n",
    "    if lowercase:\n",
    "        sentence = sentence.lower()\n",
    "    if sentence:\n",
    "        for pattern in patterns:\n",
    "            matches = re.search(pattern, sentence)\n",
    "            if matches:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Regex patterns for filtering\n",
    "exception_not_null_patterns = [\n",
    "#     '(be|equal|equals|is|are) null',\n",
    "#     'be (equal|equivalent) to null',\n",
    "#     'non-null',\n",
    "     'null'\n",
    "]\n",
    "\n",
    "exception_range_limitation_patterns = [\n",
    "    r'<|>|=',\n",
    "    r'equal|equal to|equivalent to|illegal value| is (nan|infinite|empty)',\n",
    "    r'\\b(less|smaller|greater|larger)\\b',\n",
    "    r'\\b(range|negative|positive|non-negative|non-positive)\\b'\n",
    "]\n",
    "\n",
    "exception_type_restriction_patterns = [\n",
    "    r'is( not)? an? [A-Z][a-z]+([A-Za-z_0-9\\.]*)*',\n",
    "    r'instance of|return type'\n",
    "]\n",
    "\n",
    "parameter_not_null_patterns = [\n",
    "    r'not( be)? null',\n",
    "    r'non-null',\n",
    "]\n",
    "\n",
    "parameter_range_limitation_patterns = [\n",
    "     r'<|>|=',\n",
    "     r'(less|smaller|greater|larger) than',\n",
    "     r'negative|positive|non-negative|non-positive'\n",
    "]\n",
    "\n",
    "def exception_not_null_filter(sentence):\n",
    "    return filter_by_pattern(sentence, exception_not_null_patterns, lowercase=True)\n",
    "\n",
    "def exception_range_limitation_filter(sentence):\n",
    "    return filter_by_pattern(sentence, exception_range_limitation_patterns, lowercase=True)\n",
    "\n",
    "def exception_type_restriction_filter(sentence):\n",
    "    return filter_by_pattern(sentence, exception_type_restriction_patterns, lowercase=False)\n",
    "\n",
    "def parameter_not_null_filter(sentence):\n",
    "    return filter_by_pattern(sentence, parameter_not_null_patterns, lowercase=True)\n",
    "\n",
    "def parameter_range_limitation_filter(sentence):\n",
    "    return filter_by_pattern(sentence, parameter_range_limitation_patterns, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception caveat sentences\n",
      "{'Ambiguous': 256, 'NullnessNotAllowed': 92, 'RangeLimitation': 27, 'TypeRestriction': 9, 'Dependent': 9}\n",
      "Filter results for not_null\n",
      "Correct: 92\n",
      "Retrieved: 92\n",
      "\n",
      "Filter results for range\n",
      "Correct: 27\n",
      "Retrieved: 35\n",
      "\n",
      "Filter results for type\n",
      "Correct: 9\n",
      "Retrieved: 10\n",
      "\n",
      "Parameter caveat sentences\n",
      "{'NullnessNotAllowed': 36, 'Ambiguous': 222, 'ExpectedValue': 3, 'RangeLimitation': 3}\n",
      "Filter results for not_null\n",
      "Correct: 36\n",
      "Retrieved: 37\n",
      "\n",
      "Filter results for range\n",
      "Correct: 3\n",
      "Retrieved: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exception_filters = {\n",
    "    'not_null': (exception_not_null_filter, 'NullnessNotAllowed'),\n",
    "    'range': (exception_range_limitation_filter, 'RangeLimitation'),\n",
    "    'type': (exception_type_restriction_filter, 'TypeRestriction')\n",
    "}\n",
    "\n",
    "parameter_filters = {\n",
    "    'not_null': (parameter_not_null_filter, 'NullnessNotAllowed'),\n",
    "    'range': (parameter_range_limitation_filter, 'RangeLimitation')\n",
    "}\n",
    "\n",
    "def analyse_labelled_results(file, filters):\n",
    "    with open(file) as f:\n",
    "        counts = {}\n",
    "        c = 0\n",
    "        for line in f:\n",
    "            obj = ujson.loads(line)\n",
    "\n",
    "            if obj['labels']:\n",
    "                c += 1\n",
    "                if c > 384:\n",
    "                    break\n",
    "\n",
    "                for label in obj['labels']:\n",
    "                    if not label in counts:\n",
    "                        counts[label] = 1\n",
    "                    else:\n",
    "                        counts[label] += 1\n",
    "        print(counts)\n",
    "\n",
    "        for key in filters:\n",
    "            print('Filter results for {}'.format(key))\n",
    "            correct, retrieved = 0, 0\n",
    "            c = 0\n",
    "            f.seek(0)\n",
    "            for line in f:\n",
    "                obj = ujson.loads(line)\n",
    "\n",
    "                if obj['labels']:\n",
    "                    c += 1\n",
    "                    if c > 384:\n",
    "                        break\n",
    "\n",
    "                    if filters[key][0](obj['text']):\n",
    "                        retrieved += 1\n",
    "                        if filters[key][1] in obj['labels']:\n",
    "                            correct += 1\n",
    "#                         else:\n",
    "#                             print(obj)\n",
    "#                     elif filters[key][1] in obj['labels']:\n",
    "#                         print('MISS')\n",
    "#                         print(obj)\n",
    "\n",
    "            print('Correct: {}'.format(correct))\n",
    "            print('Retrieved: {}\\n'.format(retrieved))\n",
    "  \n",
    "# Test filtering rules\n",
    "print('Exception caveat sentences')\n",
    "analyse_labelled_results('./labelled_data/labelled_exception_full.jsonl', exception_filters)\n",
    "print('Parameter caveat sentences')\n",
    "analyse_labelled_results('./labelled_data/labelled_parameter_full.jsonl', parameter_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered results: 3844\n",
      "Unique results: 1447\n",
      "\n",
      "Filtered results: 1202\n",
      "Unique results: 495\n",
      "\n",
      "Filtered results: 1946\n",
      "Unique results: 834\n",
      "\n",
      "Filtered results: 335\n",
      "Unique results: 193\n",
      "\n",
      "Filtered results: 208\n",
      "Unique results: 149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method_caveat_df = pd.DataFrame(method_caveats)\n",
    "parameter_caveat_df = pd.DataFrame(parameter_caveats)\n",
    "exception_caveat_df = pd.DataFrame(exception_caveats)\n",
    "\n",
    "def get_unique_filtered_df(df, filter_func):\n",
    "    filtered_df = df[df['sentence'].apply(filter_func)]\n",
    "    unique_df = filtered_df.drop_duplicates('sentence').sample(frac=1)\n",
    "    print('Filtered results: {}'.format(len(filtered_df.index)))\n",
    "    print('Unique results: {}\\n'.format(len(unique_df.index)))\n",
    "    return unique_df\n",
    "\n",
    "# Not null exception\n",
    "not_null_exception_df = get_unique_filtered_df(exception_caveat_df, exception_not_null_filter)\n",
    "\n",
    "# Not null paramater\n",
    "not_null_parameter_df = get_unique_filtered_df(parameter_caveat_df, parameter_not_null_filter)\n",
    "\n",
    "# Range limitation exception\n",
    "range_limit_exception_df = get_unique_filtered_df(exception_caveat_df, exception_range_limitation_filter)\n",
    "\n",
    "# Range limitation parameter\n",
    "range_limit_parameter_df = get_unique_filtered_df(parameter_caveat_df, parameter_range_limitation_filter)\n",
    "\n",
    "# Type restriction exception\n",
    "type_restrict_exception_df = get_unique_filtered_df(exception_caveat_df, exception_type_restriction_filter)\n",
    "\n",
    "def create_annotation_file(df, size, out_path, include_obj=False):\n",
    "    with open(out_path, 'w+') as out_f:\n",
    "        c = 0\n",
    "        for i in df.index:\n",
    "            c += 1\n",
    "            if c == 1:\n",
    "                out_f.write('-----------------------------')\n",
    "            \n",
    "            if c > size:\n",
    "                break\n",
    "            \n",
    "            out_f.write(str(i) + '\\n')\n",
    "            out_f.write(df.loc[i, 'signature'] + '\\n')\n",
    "            if include_obj:\n",
    "                out_f.write(df.loc[i,'obj'] + '\\n')\n",
    "            out_f.write(df.loc[i, 'sentence'] + '\\n\\n')\n",
    "            out_f.write('-----------------------------')\n",
    "            \n",
    "\n",
    "# create_annotation_file(type_restrict_exception_df, 100, './output/labelled_caveat_rules/type_restrict_exception.txt')\n",
    "create_annotation_file(not_null_exception_df, 100, './output/labelled_caveat_rules/not_null_exception.txt')\n",
    "create_annotation_file(not_null_parameter_df, 100, './output/labelled_caveat_rules/not_null_parameter.txt', True)\n",
    "create_annotation_file(range_limit_exception_df, 100, './output/labelled_caveat_rules/range_limit_exception.txt')\n",
    "create_annotation_file(range_limit_parameter_df, 100, './output/labelled_caveat_rules/range_limit_parameter.txt', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "90\n",
      "72\n",
      "49\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "def read_labelled_rule_results(path, parser, rule_start=3, offset=4):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        indices = [re.sub(\"[^0-9]\", \"\", line) for line in lines[::offset]]\n",
    "        rules = [line.strip() for line in lines[rule_start::offset]]\n",
    "        \n",
    "        if len(indices) > len(rules):\n",
    "            indices = indices[:len(rules)]\n",
    "        \n",
    "        results = {}\n",
    "        for i, val in enumerate(indices):\n",
    "            results[val] = parser(rules[i])\n",
    "            \n",
    "        return results\n",
    "    \n",
    "def or_parser(expression):\n",
    "    if expression == '':\n",
    "        return None\n",
    "    return expression.split('||')\n",
    "\n",
    "def type_parser(expression):\n",
    "    if expression == '':\n",
    "        return None\n",
    "    \n",
    "    expressions = expression.split(' & ')\n",
    "    results = []\n",
    "    for exp in expressions:\n",
    "        components = exp.split(' -> ')\n",
    "        types = components[1].split('||')\n",
    "        negated = components[0][0] == '!'\n",
    "        \n",
    "        obj = components[0]\n",
    "        if components[0][0] == '!':\n",
    "            obj = components[0][1:]\n",
    "        results.append({'obj': obj, 'types': types, 'negated':negated})\n",
    "    \n",
    "    return results\n",
    "        \n",
    "not_null_exception_results = read_labelled_rule_results('./labelled_data/not_null_exception.txt', or_parser)\n",
    "print(len([x for x in not_null_exception_results if not_null_exception_results[x]]))\n",
    "\n",
    "not_null_parameter_results = read_labelled_rule_results('./labelled_data/not_null_parameter.txt', or_parser, 4, 5)\n",
    "print(len([x for x in not_null_parameter_results if not_null_parameter_results[x]]))\n",
    "\n",
    "range_limit_exception_results = read_labelled_rule_results('./labelled_data/range_limit_exception.txt', or_parser)\n",
    "print(len([x for x in range_limit_exception_results if range_limit_exception_results[x]]))\n",
    "\n",
    "range_limit_parameter_results = read_labelled_rule_results('./labelled_data/range_limit_parameter.txt', or_parser, 4, 5)\n",
    "print(len([x for x in range_limit_parameter_results if range_limit_parameter_results[x]]))\n",
    "\n",
    "type_restrict_exception_results = read_labelled_rule_results('./labelled_data/type_restrict_exception.txt', type_parser)\n",
    "print(len([x for x in type_restrict_exception_results if type_restrict_exception_results[x]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_rules(api_caveat_obj):\n",
    "    skip_patterns = [\n",
    "        r'subclass|at the specified',\n",
    "        r'any .*element of .* is( not)? an?',\n",
    "        r'and ([a-z]\\w+) is( not)? an? ((?:[A-Z]\\w+(?:, )?)+)(?:or(?: a)? ([A-Z]\\w+))?',\n",
    "        r' ([a-z]\\w+) is( not)? an? ((?:[A-Z]\\w+(?:, )?)+)(?:or(?: a)? ([A-Z]\\w+))? and'\n",
    "    ]\n",
    "    for pattern in skip_patterns:\n",
    "        if re.search(pattern, api_caveat_obj['sentence']):\n",
    "            return\n",
    "    matches = re.search(r' ([a-z]\\w+) is( not)? a Class that implements interface ([A-Z]\\w+)', api_caveat_obj['sentence'])\n",
    "    if matches:\n",
    "        results = []\n",
    "        negated = matches.group(1) != None\n",
    "        results.append({'obj': matches.group(0), 'types': [matches.group(2)], 'negated': negated})\n",
    "    \n",
    "    else:\n",
    "        matches = re.findall(r' ([a-z]\\w+) is( not)? an? ((?:[A-Z]\\w+,? ?)+)(?:or ([A-Z]\\w+))?', api_caveat_obj['sentence'])\n",
    "        if matches:\n",
    "            results = []\n",
    "            for match in matches:\n",
    "                if match[0] in api_caveat_obj['parameters']:\n",
    "                    types = [e.strip() for e in match[2].split(', ') if len(e) > 0]\n",
    "                    if match[3]:\n",
    "                        types.append(match[3])\n",
    "                    # only look at class names (first char is uppercase)\n",
    "                    types = [t for t in types if t[0].isupper()]\n",
    "                    if len(types) == 0:\n",
    "                        continue\n",
    "\n",
    "                    negated = match[1] == '' # not we check the reversed negation\n",
    "                    results.append({'obj': match[0], 'types': types, 'negated': negated})\n",
    "\n",
    "            return results\n",
    "    \n",
    "def is_not_null_parameter_caveat(api_caveat_obj):\n",
    "    sentence = api_caveat_obj['sentence'].lower()\n",
    "    \n",
    "    # skip conditional\n",
    "    if 'if ' in sentence:\n",
    "        return False\n",
    "    \n",
    "    patterns = [\n",
    "        r'not( be)? null',\n",
    "        r'non-null'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, sentence):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_not_null_exception_rules(api_caveat_obj):\n",
    "    # skip additional condition patterns\n",
    "    skip_patterns = [\n",
    "        r' and .* is null',\n",
    "        r' is null and',\n",
    "        r' any of the arguments',\n",
    "        r' contains null element'\n",
    "    ]\n",
    "    \n",
    "    types = []\n",
    "    \n",
    "    for pattern in skip_patterns:\n",
    "        if re.search(pattern, api_caveat_obj['sentence']):\n",
    "            return types\n",
    "    \n",
    "    # assume the caveat is about single parameters\n",
    "    if len(api_caveat_obj['parameters']) == 1 and re.search(' null', api_caveat_obj['sentence']):\n",
    "        return api_caveat_obj['parameters']\n",
    "    \n",
    "    match = re.search(r'([Ii]f|[Ww]hen) (.*) null', api_caveat_obj['sentence'])\n",
    "    print(match)\n",
    "    if match:\n",
    "        tokens = re.sub(', ', ' ', match.group(2))\n",
    "        tokens = match.group(2).split(' ')\n",
    "        types = [t for t in tokens if t in api_caveat_obj['parameters']]\n",
    "    return set(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 40), match='if type, source, or connectionId is null'>\n",
      "{'connectionId'}\n",
      "['type', 'source', 'connectionId']\n"
     ]
    }
   ],
   "source": [
    "k = 12403\n",
    "print(get_not_null_exception_rules(not_null_exception_df.loc[k].to_dict()))\n",
    "print(not_null_exception_results[str(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'obj': 'src', 'types': ['IndexColorModel'], 'negated': True}]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_type_rules(type_restrict_exception_df.loc[12403].to_dict()))\n",
    "print(type_restrict_exception_results['1762'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16414\n",
      "16423\n",
      "7928\n",
      "5174\n",
      "8009\n",
      "16388\n",
      "16411\n",
      "7990\n",
      "10139\n",
      "14367\n",
      "12594\n",
      "12676\n",
      "16398\n",
      "12607\n",
      "MISFIND\n",
      "1762\n",
      "retrieved:15, correct:14, total: 33\n"
     ]
    }
   ],
   "source": [
    "# evaluate type rules generation via regex\n",
    "retrieved, correct, total = 0, 0, 0\n",
    "for key in type_restrict_exception_results:\n",
    "    index = int(key)\n",
    "    caveat_obj = type_restrict_exception_df.loc[index].to_dict()\n",
    "    \n",
    "    rules = get_type_rules(caveat_obj)\n",
    "    if rules:\n",
    "        retrieved += 1\n",
    "        \n",
    "        if not type_restrict_exception_results[key]:\n",
    "            print('MISFIND')\n",
    "            print(index)\n",
    "            continue\n",
    "        \n",
    "        is_correct = True\n",
    "        if not type_restrict_exception_results[key]:\n",
    "            is_correct = False\n",
    "        \n",
    "        has_match = False\n",
    "        for rule in rules:\n",
    "            match = [e for e in type_restrict_exception_results[key] if e['obj'] == rule['obj']]\n",
    "            if len(match) > 0 and match[0]['types'] == rule['types'] and match[0]['negated'] == rule['negated']:\n",
    "                has_match = True\n",
    "                break\n",
    "        \n",
    "        if is_correct and has_match:\n",
    "            print(index)\n",
    "            correct += 1\n",
    "            \n",
    "    if type_restrict_exception_results[key]:\n",
    "        total += 1\n",
    "print('retrieved:{}, correct:{}, total: {}'.format(retrieved, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4227\n",
      "retrieved:91, correct:90, total: 90\n"
     ]
    }
   ],
   "source": [
    "# evaluate not null rules (parameter sentences) generation via regex\n",
    "retrieved, correct, total = 0, 0, 0\n",
    "for key in not_null_parameter_results:\n",
    "    index = int(key)\n",
    "    caveat_obj = not_null_parameter_df.loc[index].to_dict()\n",
    "    \n",
    "    rule = is_not_null_parameter_caveat(caveat_obj)\n",
    "    if rule:\n",
    "        retrieved += 1\n",
    "        \n",
    "        if not not_null_parameter_results[key]:\n",
    "            print(index)\n",
    "            continue\n",
    "        \n",
    "        correct += 1\n",
    "            \n",
    "    if not_null_parameter_results[key]:\n",
    "        if not rule:\n",
    "            print(index)\n",
    "        total += 1\n",
    "print('retrieved:{}, correct:{}, total: {}'.format(retrieved, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3078\n",
      "WRONG\n",
      "12403\n",
      "8702\n",
      "WRONG\n",
      "12013\n",
      "WRONG\n",
      "3994\n",
      "WRONG\n",
      "14403\n",
      "8651\n",
      "12091\n",
      "12587\n",
      "WRONG\n",
      "10450\n",
      "WRONG\n",
      "12519\n",
      "WRONG\n",
      "6019\n",
      "3112\n",
      "WRONG\n",
      "14946\n",
      "WRONG\n",
      "1702\n",
      "WRONG\n",
      "949\n",
      "8146\n",
      "15643\n",
      "3364\n",
      "WRONG\n",
      "12088\n",
      "retrieved:81, correct:70, total: 79\n"
     ]
    }
   ],
   "source": [
    "# evaluate not null rules (exception sentences) generation via regex\n",
    "retrieved, correct, total = 0, 0, 0\n",
    "\n",
    "for key in not_null_exception_results:\n",
    "    index = int(key)\n",
    "    caveat_obj = not_null_exception_df.loc[index].to_dict()\n",
    "    \n",
    "    rules = get_not_null_exception_rules(caveat_obj)\n",
    "    if rules:\n",
    "        retrieved += 1\n",
    "        \n",
    "        if not not_null_exception_results[key] or set(not_null_exception_results[key]) != set(rules):\n",
    "            print('WRONG')\n",
    "            print(index)\n",
    "            continue\n",
    "        \n",
    "        correct += 1\n",
    "            \n",
    "    if not_null_exception_results[key]:\n",
    "        if not rules:\n",
    "            print(index)\n",
    "        total += 1\n",
    "print('retrieved:{}, correct:{}, total: {}'.format(retrieved, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Raised', 'VBN'), ('if', 'IN'), ('the', 'DT'), ('root', 'NN'), ('container', 'NN'), ('of', 'IN'), ('refNode', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('an', 'DT'), ('Attr', 'NNP'), ('Document', 'NNP'), ('or', 'CC'), ('DocumentFragment', 'NNP'), ('node', 'NN'), ('or', 'CC'), ('if', 'IN'), ('refNode', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('Document', 'NNP'), ('DocumentFragment', 'NNP'), ('Attr', 'NNP'), ('Entity', 'NNP'), ('or', 'CC'), ('Notation', 'NNP'), ('node', 'NN')]\n",
      "(ROOT\n",
      "  (VP\n",
      "    (VBN Raised)\n",
      "    (SBAR\n",
      "      (SBAR\n",
      "        (IN if)\n",
      "        (S\n",
      "          (NP\n",
      "            (NP (DT the) (NN root) (NN container))\n",
      "            (PP (IN of) (NP (NN refNode))))\n",
      "          (VP\n",
      "            (VBZ is)\n",
      "            (RB not)\n",
      "            (NP\n",
      "              (DT an)\n",
      "              (NNP Attr)\n",
      "              (NNP Document)\n",
      "              (CC or)\n",
      "              (NNP DocumentFragment)\n",
      "              (NN node)))))\n",
      "      (CC or)\n",
      "      (SBAR\n",
      "        (IN if)\n",
      "        (S\n",
      "          (NP (NN refNode))\n",
      "          (VP\n",
      "            (VBZ is)\n",
      "            (NP\n",
      "              (NP\n",
      "                (DT a)\n",
      "                (NNP Document)\n",
      "                (NNP DocumentFragment)\n",
      "                (NNP Attr)\n",
      "                (NNP Entity))\n",
      "              (CC or)\n",
      "              (NP (NNP Notation) (NN node)))))))))\n"
     ]
    }
   ],
   "source": [
    "def preprocess(sentence):\n",
    "    if sentence[-1] == '.':\n",
    "        sentence = sentence[:-1]\n",
    "    \n",
    "    sentence = re.sub(r'[-]', ' ', sentence)\n",
    "    sentence = re.sub(r'[^\\w\\. ]', '', sentence)\n",
    "    # remove brackets surrounding text\n",
    "    matches = re.findall(r' ([^)])', sentence)\n",
    "    for match in matches:\n",
    "        sentence = re.sub(match, match[0], sentence)\n",
    "    return sentence\n",
    "\n",
    "def tokenize(sentence):    \n",
    "    return sentence.split()\n",
    "\n",
    "test = 'Raised if the root container of refNode is not an Attr, Document, or DocumentFragment node or if refNode is a Document, DocumentFragment, Attr, Entity, or Notation node'\n",
    "processed_text = tokenize(preprocess(test))\n",
    "print(parser.tag(processed_text))\n",
    "print(next(next(parser.parse_sents([processed_text]))))\n",
    "# next(parser.raw_parse('if number is null or not an instance of Number')).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
