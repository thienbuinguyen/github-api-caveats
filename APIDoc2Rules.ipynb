{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser, CoreNLPParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the non-dreprecated java doc caveat sentences of methods (parameters or exception level)\n",
    "caveat_files_dir = './output/java_12_spec_caveat_sentences_revised/'\n",
    "caveats = []\n",
    "method_caveats = []\n",
    "parameter_caveats = []\n",
    "exception_caveats = []\n",
    "\n",
    "files = sorted(glob.glob(caveat_files_dir + '*.json'))\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        arr = ujson.load(f)\n",
    "        full_class_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        simple_class_name = full_class_name.split('.')[-1]\n",
    "        \n",
    "        for caveat in arr:\n",
    "            if not caveat['deprecated'] and 'name' in caveat:\n",
    "                \n",
    "                # collect the name of parameters\n",
    "                collected = False\n",
    "                parameters = []\n",
    "                for misc_obj in caveat['caveat_misc']:\n",
    "                    if misc_obj['name'] == 'Parameters:':\n",
    "                        for obj in misc_obj['list']:\n",
    "                            parameters.append(obj['parameter'])\n",
    "                        collected = True\n",
    "                        break\n",
    "                        \n",
    "                for sentence in caveat['sentences']:\n",
    "                    e = {\n",
    "                        'obj': '',\n",
    "                        'simple_class_name': simple_class_name,\n",
    "                        'full_class_name': full_class_name,\n",
    "                        'api': caveat['name'],\n",
    "                        'signature': caveat['signature'],\n",
    "                        'sentence': sentence,\n",
    "                        'parameters': parameters,\n",
    "                        'type': 'method'\n",
    "                    }\n",
    "                    method_caveats.append(e)\n",
    "                    caveats.append(e)\n",
    "\n",
    "                if collected:\n",
    "                    # add all parameter and exception level sentences\n",
    "                    for misc_obj in caveat['caveat_misc']:\n",
    "                        if misc_obj['name'] in ['Parameters:', 'Throws:']:\n",
    "                            for obj in misc_obj['list']:\n",
    "                                for misc_sentence in obj['sentences']:\n",
    "                                    if misc_obj['name'] == 'Parameters:':\n",
    "                                        e = {\n",
    "                                            'obj': obj['parameter'],\n",
    "                                            'simple_class_name': simple_class_name,\n",
    "                                            'full_class_name': full_class_name,\n",
    "                                            'api': caveat['name'],\n",
    "                                            'signature': caveat['signature'],\n",
    "                                            'sentence': misc_sentence,\n",
    "                                            'parameters': parameters,\n",
    "                                            'type': 'parameter'\n",
    "                                        }\n",
    "                                        parameter_caveats.append(e)\n",
    "                                        caveats.append(e)\n",
    "                                    else:\n",
    "                                        e = {\n",
    "                                            'obj': obj['exception'],\n",
    "                                            'simple_class_name': simple_class_name,\n",
    "                                            'full_class_name': full_class_name,\n",
    "                                            'api': caveat['name'],\n",
    "                                            'signature': caveat['signature'],\n",
    "                                            'sentence': misc_sentence,\n",
    "                                            'parameters': parameters,\n",
    "                                            'type': 'exception'\n",
    "                                        }\n",
    "                                        exception_caveats.append(e)\n",
    "                                        caveats.append(e)\n",
    "\n",
    "caveats_df = pd.DataFrame(caveats)\n",
    "method_caveat_df = pd.DataFrame(method_caveats)\n",
    "parameter_caveat_df = pd.DataFrame(parameter_caveats)\n",
    "exception_caveat_df = pd.DataFrame(exception_caveats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_pattern(sentence, patterns, lowercase):\n",
    "    if lowercase:\n",
    "        sentence = sentence.lower()\n",
    "    if sentence:\n",
    "        for pattern in patterns:\n",
    "            matches = re.search(pattern, sentence)\n",
    "            if matches:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Regex patterns for filtering\n",
    "exception_not_null_patterns = [\n",
    "     'null'\n",
    "]\n",
    "\n",
    "exception_range_limitation_patterns = [\n",
    "    r'<|>|=',\n",
    "    r'equal|equal to|equivalent to|illegal value| is (nan|infinite|empty)',\n",
    "    r'\\b(less|smaller|greater|larger)\\b',\n",
    "    r'\\b(range|negative|positive|non-negative|non-positive)\\b'\n",
    "]\n",
    "\n",
    "exception_type_restriction_patterns = [\n",
    "    r'is( not)? an? [A-Z][a-z]+([A-Za-z_0-9\\.]*)*',\n",
    "    r'instance of|return type'\n",
    "]\n",
    "\n",
    "parameter_not_null_patterns = [\n",
    "    r'not( be)? null',\n",
    "    r'non-null',\n",
    "]\n",
    "\n",
    "parameter_range_limitation_patterns = [\n",
    "     r'<|>|=',\n",
    "     r'(less|smaller|greater|larger) than',\n",
    "     r'negative|positive|non-negative|non-positive'\n",
    "]\n",
    "\n",
    "def exception_not_null_filter(sentence):\n",
    "    return filter_by_pattern(sentence, exception_not_null_patterns, lowercase=True)\n",
    "\n",
    "def exception_range_limitation_filter(sentence):\n",
    "    return filter_by_pattern(sentence, exception_range_limitation_patterns, lowercase=True)\n",
    "\n",
    "def exception_type_restriction_filter(sentence):\n",
    "    return filter_by_pattern(sentence, exception_type_restriction_patterns, lowercase=False)\n",
    "\n",
    "def parameter_not_null_filter(sentence):\n",
    "    return filter_by_pattern(sentence, parameter_not_null_patterns, lowercase=True)\n",
    "\n",
    "def parameter_range_limitation_filter(sentence):\n",
    "    return filter_by_pattern(sentence, parameter_range_limitation_patterns, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception caveat sentences\n",
      "{'Ambiguous': 256, 'NullnessNotAllowed': 92, 'RangeLimitation': 27, 'TypeRestriction': 9, 'Dependent': 9}\n",
      "Filter results for not_null\n",
      "Correct: 92\n",
      "Retrieved: 92\n",
      "\n",
      "Filter results for range\n",
      "Correct: 27\n",
      "Retrieved: 35\n",
      "\n",
      "Filter results for type\n",
      "Correct: 9\n",
      "Retrieved: 10\n",
      "\n",
      "Parameter caveat sentences\n",
      "{'NullnessNotAllowed': 36, 'Ambiguous': 222, 'ExpectedValue': 3, 'RangeLimitation': 3}\n",
      "Filter results for not_null\n",
      "Correct: 36\n",
      "Retrieved: 37\n",
      "\n",
      "Filter results for range\n",
      "Correct: 3\n",
      "Retrieved: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exception_filters = {\n",
    "    'not_null': (exception_not_null_filter, 'NullnessNotAllowed'),\n",
    "    'range': (exception_range_limitation_filter, 'RangeLimitation'),\n",
    "    'type': (exception_type_restriction_filter, 'TypeRestriction')\n",
    "}\n",
    "\n",
    "parameter_filters = {\n",
    "    'not_null': (parameter_not_null_filter, 'NullnessNotAllowed'),\n",
    "    'range': (parameter_range_limitation_filter, 'RangeLimitation')\n",
    "}\n",
    "\n",
    "def analyse_labelled_results(file, filters):\n",
    "    with open(file) as f:\n",
    "        counts = {}\n",
    "        c = 0\n",
    "        for line in f:\n",
    "            obj = ujson.loads(line)\n",
    "\n",
    "            if obj['labels']:\n",
    "                c += 1\n",
    "                if c > 384:\n",
    "                    break\n",
    "\n",
    "                for label in obj['labels']:\n",
    "                    if not label in counts:\n",
    "                        counts[label] = 1\n",
    "                    else:\n",
    "                        counts[label] += 1\n",
    "        print(counts)\n",
    "\n",
    "        for key in filters:\n",
    "            print('Filter results for {}'.format(key))\n",
    "            correct, retrieved = 0, 0\n",
    "            c = 0\n",
    "            f.seek(0)\n",
    "            for line in f:\n",
    "                obj = ujson.loads(line)\n",
    "\n",
    "                if obj['labels']:\n",
    "                    c += 1\n",
    "                    if c > 384:\n",
    "                        break\n",
    "\n",
    "                    if filters[key][0](obj['text']):\n",
    "                        retrieved += 1\n",
    "                        if filters[key][1] in obj['labels']:\n",
    "                            correct += 1\n",
    "            print('Correct: {}'.format(correct))\n",
    "            print('Retrieved: {}\\n'.format(retrieved))\n",
    "\n",
    "print('Exception caveat sentences')\n",
    "analyse_labelled_results('./labelled_data/labelled_exception_full.jsonl', exception_filters)\n",
    "print('Parameter caveat sentences')\n",
    "analyse_labelled_results('./labelled_data/labelled_parameter_full.jsonl', parameter_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered results: 3844\n",
      "Unique results: 1447\n",
      "\n",
      "Filtered results: 1202\n",
      "Unique results: 495\n",
      "\n",
      "Filtered results: 1946\n",
      "Unique results: 834\n",
      "\n",
      "Filtered results: 335\n",
      "Unique results: 193\n",
      "\n",
      "Filtered results: 208\n",
      "Unique results: 149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method_caveat_df = pd.DataFrame(method_caveats)\n",
    "parameter_caveat_df = pd.DataFrame(parameter_caveats)\n",
    "exception_caveat_df = pd.DataFrame(exception_caveats)\n",
    "\n",
    "def get_unique_filtered_df(df, filter_func):\n",
    "    filtered_df = df[df['sentence'].apply(filter_func)]\n",
    "    unique_df = filtered_df.drop_duplicates('sentence').sample(frac=1)\n",
    "    print('Filtered results: {}'.format(len(filtered_df.index)))\n",
    "    print('Unique results: {}\\n'.format(len(unique_df.index)))\n",
    "    return unique_df\n",
    "\n",
    "# Not null exception\n",
    "not_null_exception_df = get_unique_filtered_df(exception_caveat_df, exception_not_null_filter)\n",
    "\n",
    "# Not null paramater\n",
    "not_null_parameter_df = get_unique_filtered_df(parameter_caveat_df, parameter_not_null_filter)\n",
    "\n",
    "# Range limitation exception\n",
    "range_limit_exception_df = get_unique_filtered_df(exception_caveat_df, exception_range_limitation_filter)\n",
    "\n",
    "# Range limitation parameter\n",
    "range_limit_parameter_df = get_unique_filtered_df(parameter_caveat_df, parameter_range_limitation_filter)\n",
    "\n",
    "# Type restriction exception\n",
    "type_restrict_exception_df = get_unique_filtered_df(exception_caveat_df, exception_type_restriction_filter)\n",
    "\n",
    "def create_annotation_file(df, size, out_path, include_obj=False):\n",
    "    with open(out_path, 'w+') as out_f:\n",
    "        c = 0\n",
    "        for i in df.index:\n",
    "            c += 1\n",
    "            if c == 1:\n",
    "                out_f.write('-----------------------------')\n",
    "            \n",
    "            if c > size:\n",
    "                break\n",
    "            \n",
    "            out_f.write(str(i) + '\\n')\n",
    "            out_f.write(df.loc[i, 'signature'] + '\\n')\n",
    "            if include_obj:\n",
    "                out_f.write(df.loc[i,'obj'] + '\\n')\n",
    "            out_f.write(df.loc[i, 'sentence'] + '\\n\\n')\n",
    "            out_f.write('-----------------------------')\n",
    "            \n",
    "\n",
    "# create_annotation_file(type_restrict_exception_df, 100, './output/labelled_caveat_rules/type_restrict_exception.txt')\n",
    "# create_annotation_file(not_null_exception_df, 100, './output/labelled_caveat_rules/not_null_exception.txt')\n",
    "# create_annotation_file(not_null_parameter_df, 100, './output/labelled_caveat_rules/not_null_parameter.txt', True)\n",
    "# create_annotation_file(range_limit_exception_df, 100, './output/labelled_caveat_rules/range_limit_exception.txt')\n",
    "# create_annotation_file(range_limit_parameter_df, 100, './output/labelled_caveat_rules/range_limit_parameter.txt', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "90\n",
      "72\n",
      "49\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "def read_labelled_rule_results(path, parser, rule_start=3, offset=4):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        indices = [re.sub(\"[^0-9]\", \"\", line) for line in lines[::offset]]\n",
    "        rules = [line.strip() for line in lines[rule_start::offset]]\n",
    "        \n",
    "        if len(indices) > len(rules):\n",
    "            indices = indices[:len(rules)]\n",
    "        \n",
    "        results = {}\n",
    "        for i, val in enumerate(indices):\n",
    "            results[val] = parser(rules[i])\n",
    "            \n",
    "        return results\n",
    "    \n",
    "def or_parser(expression):\n",
    "    if expression == '':\n",
    "        return None\n",
    "    return expression.split('||')\n",
    "\n",
    "def type_parser(expression):\n",
    "    if expression == '':\n",
    "        return None\n",
    "    \n",
    "    expressions = expression.split(' & ')\n",
    "    results = []\n",
    "    for exp in expressions:\n",
    "        components = exp.split(' -> ')\n",
    "        types = components[1].split('||')\n",
    "        negated = components[0][0] == '!'\n",
    "        \n",
    "        obj = components[0]\n",
    "        if components[0][0] == '!':\n",
    "            obj = components[0][1:]\n",
    "        results.append({'obj': obj, 'types': types, 'negated':negated})\n",
    "    \n",
    "    return results\n",
    "        \n",
    "not_null_exception_results = read_labelled_rule_results('./labelled_data/not_null_exception.txt', or_parser)\n",
    "print(len([x for x in not_null_exception_results if not_null_exception_results[x]]))\n",
    "\n",
    "not_null_parameter_results = read_labelled_rule_results('./labelled_data/not_null_parameter.txt', or_parser, 4, 5)\n",
    "print(len([x for x in not_null_parameter_results if not_null_parameter_results[x]]))\n",
    "\n",
    "range_limit_exception_results = read_labelled_rule_results('./labelled_data/range_limit_exception.txt', or_parser)\n",
    "print(len([x for x in range_limit_exception_results if range_limit_exception_results[x]]))\n",
    "\n",
    "range_limit_parameter_results = read_labelled_rule_results('./labelled_data/range_limit_parameter.txt', or_parser, 4, 5)\n",
    "print(len([x for x in range_limit_parameter_results if range_limit_parameter_results[x]]))\n",
    "\n",
    "type_restrict_exception_results = read_labelled_rule_results('./labelled_data/type_restrict_exception.txt', type_parser)\n",
    "print(len([x for x in type_restrict_exception_results if type_restrict_exception_results[x]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_rules(api_caveat_obj):\n",
    "    skip_patterns = [\n",
    "        r'subclass|at the specified',\n",
    "        r'any .*element of .* is( not)? an?',\n",
    "        r'and ([a-z]\\w+) is( not)? an? ((?:[A-Z]\\w+(?:, )?)+)(?:or(?: a)? ([A-Z]\\w+))?',\n",
    "        r' ([a-z]\\w+) is( not)? an? ((?:[A-Z]\\w+(?:, )?)+)(?:or(?: a)? ([A-Z]\\w+))? and'\n",
    "    ]\n",
    "    for pattern in skip_patterns:\n",
    "        if re.search(pattern, api_caveat_obj['sentence']):\n",
    "            return\n",
    "    matches = re.search(r' ([a-z]\\w+) is( not)? a Class that implements interface ([A-Z]\\w+)', api_caveat_obj['sentence'])\n",
    "    if matches:\n",
    "        results = []\n",
    "        negated = matches.group(1) != None\n",
    "        results.append({'obj': matches.group(0), 'types': [matches.group(2)], 'negated': negated})\n",
    "    \n",
    "    else:\n",
    "        matches = re.findall(r' ([a-z]\\w+) is( not)? an? ((?:[A-Z]\\w+,? ?)+)(?:or ([A-Z]\\w+))?', api_caveat_obj['sentence'])\n",
    "        if matches:\n",
    "            results = []\n",
    "            for match in matches:\n",
    "                if match[0] in api_caveat_obj['parameters']:\n",
    "                    types = [e.strip() for e in match[2].split(', ') if len(e) > 0]\n",
    "                    if match[3]:\n",
    "                        types.append(match[3])\n",
    "                    # only look at class names (first char is uppercase)\n",
    "                    types = [t for t in types if t[0].isupper()]\n",
    "                    if len(types) == 0:\n",
    "                        continue\n",
    "\n",
    "                    negated = match[1] == '' # not we check the reversed negation\n",
    "                    results.append({'obj': match[0], 'types': types, 'negated': negated})\n",
    "\n",
    "            return results\n",
    "    \n",
    "def is_not_null_parameter_caveat(api_caveat_obj):\n",
    "    sentence = api_caveat_obj['sentence'].lower()\n",
    "    \n",
    "    # skip conditionals\n",
    "    if r'if\\b' in sentence:\n",
    "        return False\n",
    "    \n",
    "    patterns = [\n",
    "        r'not( be)? null',\n",
    "        r'non-null'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, sentence):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_not_null_exception_rules(api_caveat_obj):\n",
    "    # skip additional condition patterns\n",
    "    skip_patterns = [\n",
    "        r' and .* is null',\n",
    "        r' is null and',\n",
    "        r' any of the arguments',\n",
    "        r' contains null element'\n",
    "    ]\n",
    "    \n",
    "    types = []\n",
    "    \n",
    "    for pattern in skip_patterns:\n",
    "        if re.search(pattern, api_caveat_obj['sentence']):\n",
    "            return types\n",
    "    \n",
    "    # assume the caveat is about single parameters\n",
    "    if len(api_caveat_obj['parameters']) == 1 and re.search(' null', api_caveat_obj['sentence']):\n",
    "        return api_caveat_obj['parameters']\n",
    "    \n",
    "    match = re.search(r'([Ii]f|[Ww]hen) (.*) null', api_caveat_obj['sentence'])\n",
    "    if match:\n",
    "        tokens = re.sub(', ', ' ', match.group(2)).split()\n",
    "        types = [t for t in tokens if t in api_caveat_obj['parameters']]\n",
    "    return list(set(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence normalisation functions\n",
    "\n",
    "def normalise_operators(sentence):\n",
    "    # list of expression substitutions for logical phrases, note ordering is used\n",
    "    patterns = [\n",
    "        (r'(not? (less|shorter) than)', '>='),\n",
    "        (r'(not? (greater|larger|longer) than)', '<='),\n",
    "        (r'((greater|larger) than or equal to)', '>='),\n",
    "        (r'((less|shorter) than or equal to)', '<='),\n",
    "        (r'((less|shorter) than)', '<'),\n",
    "        (r'((greater|larger|longer) than)', '>'),\n",
    "        (r'((is|are)? not negative)', '>= 0'),\n",
    "        (r'((is|are)? not positive)', '<= 0'),\n",
    "        (r'((is|are)? negative)', '< 0'), (r'((be)? non-negative)', '>= 0'),\n",
    "        (r'((is|are)? positive)', '< 0'), (r'((be)? non-positive)', '<= 0'),\n",
    "        (r'(not equal( to)?)', '!='),\n",
    "        (r'(equal to)', '==')\n",
    "    ]\n",
    "\n",
    "    # normalise all equality phrases\n",
    "    for t in patterns:\n",
    "        sentence = re.sub(t[0], t[1], sentence)\n",
    "                \n",
    "    return sentence\n",
    "\n",
    "def normalise_args(sentence, parameters):\n",
    "    # variable substitutions\n",
    "    variable_subs = [\n",
    "        '\\W(-?[0-9]+(?:,[0-9]+)*(?:(?:\\.[0-9]+)?[a-z]*))', # specific numeric value\n",
    "        r'\\W(\"[^\"]+\")', # simple string\n",
    "        r'\\b([A-Za-z_]+[A-Za-z_0-9]*\\.[A-Za-z_][A-Za-z_0-9]*\\([^\\)]*\\))', # class method\n",
    "        r'\\b((^(java\\.|javax\\.|org\\.))?([A-Za-z_]\\w*\\.)+\\w+)\\b', # member value of object/Class\n",
    "        r'\\b([A-Z]+_[A-Z]+(_[A-Z]+)*)\\b', # all uppercase and at least 1 underscore\n",
    "        r'\\W([a-z_][A-Za-z_0-9]*\\([^\\)]*\\))' # standalone methods \n",
    "    ]\n",
    "    \n",
    "    param_prefix = '@PARAM'\n",
    "    param_counter = 'a'        \n",
    "\n",
    "    variable_prefix = '@ARG'\n",
    "    variable_counter = 'a'\n",
    "    variable_dict = {}\n",
    "    \n",
    "    # add default mappings\n",
    "    for var in ['null']:\n",
    "        key = variable_prefix + variable_counter\n",
    "        variable_dict[key] = var\n",
    "        variable_counter = chr(ord(variable_counter) + 1)\n",
    "    \n",
    "        # replace all occurences of the default var\n",
    "        sentence = re.sub(r'\\b' + var + r'\\b', key, sentence)\n",
    "    \n",
    "    # normalise numerical values first, # specific numeric value\n",
    "    match = re.search('\\W(-?[0-9]+(\\.[0-9]+)+[a-z]?)\\W', sentence)\n",
    "    while match:\n",
    "        key = variable_prefix + str(variable_counter)\n",
    "        variable_dict[key] = match.group(1)\n",
    "        next_pattern = r'\\b' + re.escape(match.group(1)) + r'\\b'\n",
    "        sentence = re.sub(next_pattern, key, sentence)\n",
    "        variable_counter = chr(ord(variable_counter) + 1)\n",
    "\n",
    "        match = re.search('\\W(-?[0-9]+(\\.[0-9]+)+[a-z]?)\\W', sentence)\n",
    "\n",
    "    # normalise all variables/methods/fields that match predefined regex patterns\n",
    "    for pattern in variable_subs:\n",
    "        match = re.search(pattern, sentence)\n",
    "        while match:\n",
    "            key = variable_prefix + str(variable_counter)\n",
    "            variable_dict[key] = match.group(1)\n",
    "            next_pattern = re.escape(match.group(1))\n",
    "            sentence = re.sub(next_pattern, key, sentence)\n",
    "            variable_counter = chr(ord(variable_counter) + 1)\n",
    "\n",
    "            match = re.search(pattern, sentence)\n",
    "     \n",
    "     # normalise all API call parameters\n",
    "    for parameter in parameters:\n",
    "        key = param_prefix + param_counter\n",
    "        variable_dict[key] = parameter\n",
    "        sentence = re.sub(r'\\b'+parameter+r'\\b', key, sentence)\n",
    "        param_counter = chr(ord(param_counter) + 1)\n",
    "\n",
    "    return sentence, variable_dict\n",
    "\n",
    "def normalise_enum_lists(sentence):\n",
    "    # locate enumerations (lists of items)\n",
    "    list_dict = {}\n",
    "    list_counter = 0\n",
    "    list_prefix = '@LIST'\n",
    "    pattern = '\\W((@ARG\\w|)(?:,\\s*(@ARG\\w)\\s*)+,?\\s*or\\s*(@ARG\\w))'\n",
    "    match = re.search(pattern, sentence)\n",
    "\n",
    "    while match:\n",
    "        key = list_prefix + str(list_counter)\n",
    "        sentence = re.sub(match.group(1), key, sentence)\n",
    "        list_dict[key] = match.group(1)\n",
    "\n",
    "        match = re.search(pattern, sentence)\n",
    "        list_counter += 1\n",
    "        \n",
    "    return sentence, list_dict\n",
    "\n",
    "def normalise_explicit_expressions(sentence):\n",
    "    expressions_dict = {}\n",
    "    expression_prefix = '@EEXPR'\n",
    "    expression_counter = 0\n",
    "    start_index = 0\n",
    "    bracket_counter = 0\n",
    "    old_len = 0\n",
    "    first = True\n",
    "\n",
    "    while first or len(expressions_dict) != old_len:\n",
    "        first = False\n",
    "        old_len = len(expressions_dict)\n",
    "        for i, c in enumerate(sentence):\n",
    "            if c == '(': \n",
    "                if bracket_counter == 0:\n",
    "                    start_index = i\n",
    "                \n",
    "                bracket_counter += 1\n",
    "            elif c == ')':\n",
    "                bracket_counter -= 1\n",
    "                if bracket_counter == 0:\n",
    "                    substr = sentence[start_index:i+1]\n",
    "                    start_index = i + 1\n",
    "\n",
    "                    if re.search(r'-|\\+|\\*|/|<|<=|>|>=|==|!=|&&|\\|\\||\\.\\.', substr):\n",
    "                        escaped = re.escape(substr)\n",
    "                        key = expression_prefix + str(expression_counter)\n",
    "                        expressions_dict[key] = substr\n",
    "                        sentence = re.sub(escaped, key, sentence)\n",
    "                        expression_counter += 1\n",
    "\n",
    "    return sentence, expressions_dict\n",
    "\n",
    "def normalise_spaces(sentence):\n",
    "    # remove left-side spaces around operators if adjacent to VAR* or EXPR* modifiers\n",
    "    seen_expressions = set()\n",
    "    match = re.search(r'(@ARG\\w|@PARAM\\w|@IEXPR\\w)\\s+(-|\\+|\\*|/|\\.\\.)', sentence)\n",
    "    while match and not match in seen_expressions:\n",
    "        sub = match.group(1) + match.group(2)\n",
    "        escaped = re.escape(match.group(0))\n",
    "        sentence = re.sub(escaped, sub, sentence)\n",
    "        \n",
    "        seen_expressions.add(match)\n",
    "        match = re.search(r'(@ARG\\w|@PARAM\\w|@IEXPR\\w)\\s+(-|\\+|\\*|/|\\.\\.)', sentence)\n",
    "\n",
    "    # remove right-side spaces around operators if adjacent to VAR*, PARAM* EXPR* modifiers\n",
    "    match = re.search(r'(-|\\+|\\*|/|<|<=|>|>=|==|!=|&&|\\|\\||&|\\.\\.)\\s+(@ARG\\w|@PARAM\\w|@IEXPR\\w)', sentence)\n",
    "    while match and not match in seen_expressions:\n",
    "        sub = match.group(1) + match.group(2)\n",
    "        escaped = re.escape(match.group(0))\n",
    "        sentence = re.sub(escaped, sub, sentence)\n",
    "\n",
    "        seen_expressions.add(match)\n",
    "        match = re.search(r'(-|\\+|\\*|/|<|<=|>|>=|==|!=|&&|\\|\\||&|\\.\\.)\\s+(@ARG\\w|@PARAM\\w|@IEXPR\\w)', sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def normalise_ranges(sentence):\n",
    "    patterns = [\n",
    "        r'\\b((?:range )?(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)\\.\\.(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w))\\b',\n",
    "        r'\\b(\\[?(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)\\.\\.(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)\\]?)\\b',\n",
    "        r'\\b((?:[Ff]rom|range) (@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w) to (@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w))\\b',\n",
    "        r'between ((@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w) and (@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w))',\n",
    "        r'((@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)\\s*<=?\\s*(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)\\s*<=?\\s*(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w))',\n",
    "        r'((@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)\\s*>=?\\s*(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)\\s*>=?\\s*(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w))'\n",
    "    ]\n",
    "    \n",
    "    range_dict = {}\n",
    "    range_prefix = '@RANGE'\n",
    "    counter = 0\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, sentence)\n",
    "        while match:\n",
    "            key = range_prefix + str(counter)\n",
    "            range_dict[key] = match.group(1)\n",
    "            next_pattern = re.escape(match.group(1))\n",
    "            sentence = re.sub(next_pattern, key, sentence)\n",
    "            counter += 1\n",
    "            match = re.search(pattern, sentence)\n",
    "    \n",
    "    return sentence, range_dict    \n",
    "    \n",
    "def tokenize(sentence): \n",
    "    # substitute '#' to separate composite sentences\n",
    "    sentence = re.sub(r'[^A-Za-z0-9<>=! @]', ' ', sentence)\n",
    "    return sentence.split()\n",
    "\n",
    "def filter_tokens(tokens):\n",
    "    return [x for x in tokens if re.search('^(@\\w+|<|<=|>|>=|==|!=|&&|\\|\\||if|then|and|or|either|is|not|true|false)$', x)]\n",
    "\n",
    "def normalise_implicit_expressions(tokens):\n",
    "    expr = {}\n",
    "    prefix = '@IEXPR'\n",
    "    counter = 0\n",
    "    new_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        match = re.search(r'(-|\\+|\\*|/|<|<=|>|>=|==|!=|&&|\\|\\||&|\\.\\.)@', token)\n",
    "        if match:\n",
    "            key = prefix + str(counter)\n",
    "            expr[key] = token\n",
    "            token = key\n",
    "            counter += 1\n",
    "            \n",
    "        new_tokens.append(token)\n",
    "\n",
    "    return new_tokens, expr\n",
    "\n",
    "def normalise(sentence, parameters):\n",
    "    if sentence[-1] == '.':\n",
    "        sentence = sentence[:-1]\n",
    "    \n",
    "    # apply all sentence normalisations\n",
    "    sentence = normalise_operators(sentence)\n",
    "    sentence, args = normalise_args(sentence, parameters)\n",
    "    sentence, lists = normalise_enum_lists(sentence)\n",
    "    sentence, explicit_exprs = normalise_explicit_expressions(sentence)\n",
    "    sentence = normalise_spaces(sentence)\n",
    "    sentence, ranges = normalise_ranges(sentence)\n",
    "        \n",
    "    tokens = tokenize(sentence)\n",
    "    tokens, implicit_exprs = normalise_implicit_expressions(tokens)\n",
    "    \n",
    "    for arg in args:\n",
    "        for expr in explicit_exprs:\n",
    "            if arg in explicit_exprs[expr]:\n",
    "                explicit_exprs[expr] = re.sub(arg, args[arg], explicit_exprs[expr])\n",
    "        \n",
    "        for expr in implicit_exprs:\n",
    "            if arg in implicit_exprs[expr]:\n",
    "                implicit_exprs[expr] = re.sub(arg, args[arg], implicit_exprs[expr])\n",
    "\n",
    "    placeholders = {}\n",
    "    placeholders.update(args)\n",
    "    placeholders.update(lists)\n",
    "    placeholders.update(ranges)\n",
    "    placeholders.update(explicit_exprs)\n",
    "    placeholders.update(implicit_exprs)\n",
    "        \n",
    "    return tokens, placeholders\n",
    "\n",
    "def resolve_rule_placeholders(rules, placeholders):\n",
    "    resolved_rules = []\n",
    "    \n",
    "    # substitute all placeholders with original value\n",
    "    for rule in rules:\n",
    "        resolved_param = rule['param']\n",
    "        \n",
    "        if resolved_param in placeholders:\n",
    "            resolved_param = placeholders[resolved_param]\n",
    "        \n",
    "        resolved_constraint = rule['constraint']         \n",
    "        match = re.search(r'(@\\w+)', resolved_constraint)\n",
    "        while match:\n",
    "            resolved_constraint = re.sub(re.escape(match.group(1)), placeholders[match.group(1)], resolved_constraint)\n",
    "            match = re.search(r'(@\\w+)', resolved_constraint)\n",
    "        \n",
    "        op = None\n",
    "        if 'op' in rule:\n",
    "            op = rule['op']\n",
    "        else:\n",
    "            if len(resolved_constraint) > 1:\n",
    "                if resolved_constraint[:2] in ['<=', '>=', '==', '!=']:\n",
    "                    op = resolved_constraint[:2]\n",
    "                    resolved_constraint = resolved_constraint[2:]\n",
    "                elif resolved_constraint[:1] in ['<', '>', '=']:\n",
    "                    op = resolved_constraint[:1]\n",
    "                    resolved_constraint = resolved_constraint[1:]\n",
    "        \n",
    "        if op:        \n",
    "            resolved_rules.append({'param': resolved_param, 'op': op, 'constraint': resolved_constraint})\n",
    "    \n",
    "    return resolved_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_rules = {\n",
    "    '<': '>',\n",
    "    '>': '<',\n",
    "    '>=': '<=',\n",
    "    '<=': '>='\n",
    "}\n",
    "\n",
    "negate_rules = {\n",
    "    '>': '<=',\n",
    "    '<': '>=',\n",
    "    '=': '!=',\n",
    "    '==': '!=',\n",
    "    '>=': '<',\n",
    "    '<=': '>'\n",
    "}\n",
    "\n",
    "def get_range_rules(api_caveat_obj):\n",
    "    try:\n",
    "        tokens, placeholders = normalise(api_caveat_obj['sentence'], api_caveat_obj['parameters'])\n",
    "\n",
    "        tokens = filter_tokens(tokens)\n",
    "\n",
    "        unresolved_rules = []\n",
    "        prev_params = []\n",
    "        params = []\n",
    "        negate = False\n",
    "        last_op = ''\n",
    "        cc = '' # last coordinating conjunction\n",
    "                \n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in ['not', 'false']:\n",
    "                negate = True\n",
    "            elif token.startswith('@PARAM') or token.startswith('@ARG'):\n",
    "                is_param = token.startswith('@PARAM')\n",
    "                if not is_param:\n",
    "                    for param in api_caveat_obj['parameters']:\n",
    "                         if param in placeholders[token]:\n",
    "                            is_param = True\n",
    "                            break\n",
    "                if is_param:\n",
    "                    params.append(token)\n",
    "            elif token.startswith('@IEXPR'):\n",
    "                if re.search(r'@PARAM', token):\n",
    "                    params.append(token)\n",
    "                else:\n",
    "                    if params:\n",
    "                        for param in params:\n",
    "                            unresolved_rules.append({'param': param, 'constraint': token})\n",
    "\n",
    "                        prev_params = params.copy()\n",
    "                        params.clear()\n",
    "                    elif prev_params:\n",
    "                        for param in prev_params:\n",
    "                            unresolved_rules.append({'param': param, 'constraint': token})\n",
    "                        prev_params.clear()\n",
    "                    elif len(api_caveat_obj['parameters']) == 1:\n",
    "                        unresolved_rules.append({'param': api_caveat_obj['parameters'][0], 'constraint': token})\n",
    "\n",
    "                negate = False\n",
    "            elif token.startswith('@EEXPR'):\n",
    "                if re.search(r'(<|!|>|=|&|\\|)', placeholders[token]):\n",
    "                    for k in placeholders:\n",
    "                        if k.startswith('@PARAM') and placeholders[k] in placeholders[token]:\n",
    "                            unresolved_rules.append({'param': placeholders[k], 'constraint': placeholders[token]})\n",
    "                else:\n",
    "                    params.append(token)\n",
    "            elif token.startswith('@RANGE'):\n",
    "                match = re.search(r'(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)\\s*(<=?|>=?)\\s*(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)\\s*(<=?|>=?)\\s*(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)', placeholders[token])\n",
    "                if match:\n",
    "                    unresolved_rules.append({'param': match.group(3), \n",
    "                                             'op': reverse_rules[match.group(2)] if not negate else negate_rules[reverse_rules[match.group(2)]], \n",
    "                                             'constraint': match.group(1)})\n",
    "                    unresolved_rules.append({'param': match.group(3), \n",
    "                                             'op': match.group(4) if not negate else negate_rules[match.group(4)], \n",
    "                                             'constraint': match.group(5)})\n",
    "                else:\n",
    "                    match = re.search(r'(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w).*(@ARG\\w|@PARAM\\w|@IEXPR\\w|@EEXPR\\w)', placeholders[token])\n",
    "                    if match and match.group(1) != '' and match.group(2) != '':\n",
    "                        if params:\n",
    "                            for param in params:\n",
    "                                unresolved_rules.append({'param': param, 'op': '>=' if not negate else '<', 'constraint': match.group(1)})\n",
    "                                unresolved_rules.append({'param': param, 'op': '<=' if not negate else '>', 'constraint': match.group(2)})\n",
    "\n",
    "                            prev_params = params.copy()\n",
    "                            params.clear()\n",
    "                        elif prev_params:\n",
    "                            for param in prev_params:\n",
    "                                unresolved_rules.append({'param': param, 'op': '>=' if not negate else '<', 'constraint': match.group(1)})\n",
    "                                unresolved_rules.append({'param': param, 'op': '<=' if not negate else '>', 'constraint': match.group(2)})\n",
    "                            prev_params.clear()\n",
    "                        elif len(api_caveat_obj['parameters']) == 1:\n",
    "                            unresolved_rules.append({'param': api_caveat_obj['parameters'][0], 'op': '>=' if not negate else '<', 'constraint': match.group(1)})\n",
    "                            unresolved_rules.append({'param': api_caveat_obj['parameters'][0], 'op': '<=' if not negate else '>', 'constraint': match.group(2)})\n",
    "                        \n",
    "                negate = False\n",
    "            elif token.startswith('@LIST'):\n",
    "                list_str = lists[token]\n",
    "                list_items = [e for e in re.split(r'(or|,| )', list_str) if e.startswith('@ARG')]\n",
    "\n",
    "                if params:\n",
    "                    for param in params:\n",
    "                        for l in list_items:\n",
    "                            unresolved_rules.append({'param': param, \n",
    "                                                     'op': last_op if not negate else negate_rules[last_op], \n",
    "                                                     'constraint': l})\n",
    "\n",
    "                    prev_params = params.copy()\n",
    "                    params.clear()\n",
    "                else:\n",
    "                    for param in prev_params:\n",
    "                        for l in list_items:\n",
    "                            unresolved_rules.append({'param': param, \n",
    "                                                     'op': last_op if not negate else negate_rules[last_op], \n",
    "                                                     'constraint': l})\n",
    "                    prev_params.clear()\n",
    "                negate = False\n",
    "            elif token == 'is' and (params or len(api_caveat_obj['parameters']) == 1) and \\\n",
    "                    i + 1 < len(tokens) and tokens[i+1].startswith('@ARG'):\n",
    "                if params:\n",
    "                    for param in params:\n",
    "                        unresolved_rules.append({'param': param, \n",
    "                                                 'op': '=' if not negate else '!=', \n",
    "                                                 'constraint': tokens[i+1]})\n",
    "                    prev_params = params.copy()\n",
    "                else:\n",
    "                    unresolved_rules.append({'param': api_caveat_obj['parameters'][0], \n",
    "                                                 'op': '=' if not negate else '!=', \n",
    "                                                 'constraint': tokens[i+1]})\n",
    "                params.clear()\n",
    "            elif re.search(r'^[<!>=]+', token):\n",
    "                last_op = token\n",
    "            elif token in ['and', 'or']:\n",
    "                cc = token\n",
    "        return resolve_rule_placeholders(unresolved_rules, placeholders)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['if',\n",
       "  'the',\n",
       "  'given',\n",
       "  '@PARAMa',\n",
       "  'material',\n",
       "  'starting',\n",
       "  'at',\n",
       "  'offset',\n",
       "  'inclusive',\n",
       "  'is',\n",
       "  '@IEXPR0',\n",
       "  'bytes'],\n",
       " {'@ARGa': 'null', '@ARGb': '24', '@PARAMa': 'key', '@IEXPR0': '<24'})"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalise('if the given key material, starting at offset inclusive, is shorter than 24 bytes', ['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['downstreamHandler', 'bufferSize']\n",
      "if bufferSize <= 0\n",
      "\n",
      "['if', '@PARAMb', '@IEXPR0']\n",
      "[{'param': 'bufferSize', 'op': '<=', 'constraint': '0'}]\n"
     ]
    }
   ],
   "source": [
    "obj = exception_caveat_df.loc[4258].to_dict()\n",
    "print(obj['parameters'])\n",
    "print(obj['sentence'] + '\\n')\n",
    "print(get_range_rules(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved:15, correct:14, total: 33\n"
     ]
    }
   ],
   "source": [
    "# evaluate type rules generation via regex\n",
    "retrieved, correct, total = 0, 0, 0\n",
    "for key in type_restrict_exception_results:\n",
    "    index = int(key)\n",
    "    caveat_obj = type_restrict_exception_df.loc[index].to_dict()\n",
    "    \n",
    "    rules = get_type_rules(caveat_obj)\n",
    "    if rules:\n",
    "        retrieved += 1\n",
    "        \n",
    "        if not type_restrict_exception_results[key]:\n",
    "            continue\n",
    "        \n",
    "        is_correct = True\n",
    "        if not type_restrict_exception_results[key]:\n",
    "            is_correct = False\n",
    "        \n",
    "        has_match = False\n",
    "        for rule in rules:\n",
    "            match = [e for e in type_restrict_exception_results[key] if e['obj'] == rule['obj']]\n",
    "            if len(match) > 0 and match[0]['types'] == rule['types'] and match[0]['negated'] == rule['negated']:\n",
    "                has_match = True\n",
    "                break\n",
    "        \n",
    "        if is_correct and has_match:\n",
    "            correct += 1\n",
    "            \n",
    "    if type_restrict_exception_results[key]:\n",
    "        total += 1\n",
    "print('retrieved:{}, correct:{}, total: {}'.format(retrieved, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved:91, correct:90, total: 90\n"
     ]
    }
   ],
   "source": [
    "# evaluate not null rules (parameter sentences) generation via regex\n",
    "retrieved, correct, total = 0, 0, 0\n",
    "for key in not_null_parameter_results:\n",
    "    index = int(key)\n",
    "    caveat_obj = not_null_parameter_df.loc[index].to_dict()\n",
    "    \n",
    "    rule = is_not_null_parameter_caveat(caveat_obj)\n",
    "    if rule:\n",
    "        retrieved += 1\n",
    "        \n",
    "        if not not_null_parameter_results[key]:\n",
    "            continue\n",
    "        \n",
    "        correct += 1\n",
    "            \n",
    "    if not_null_parameter_results[key]:\n",
    "        if not rule:\n",
    "            print(index)\n",
    "        total += 1\n",
    "print('retrieved:{}, correct:{}, total: {}'.format(retrieved, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved:81, correct:75, total: 84\n"
     ]
    }
   ],
   "source": [
    "# evaluate not null rules (exception sentences) generation via regex\n",
    "retrieved, correct, total = 0, 0, 0\n",
    "\n",
    "for key in not_null_exception_results:\n",
    "    index = int(key)\n",
    "    caveat_obj = not_null_exception_df.loc[index].to_dict()\n",
    "    \n",
    "    rules = get_not_null_exception_rules(caveat_obj)\n",
    "    if rules:\n",
    "        retrieved += 1\n",
    "        \n",
    "        if not not_null_exception_results[key] or set(not_null_exception_results[key]) != set(rules):\n",
    "            continue\n",
    "        \n",
    "        correct += 1\n",
    "            \n",
    "    if not_null_exception_results[key]:\n",
    "        total += 1\n",
    "print('retrieved:{}, correct:{}, total: {}'.format(retrieved, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api</th>\n",
       "      <th>full_class_name</th>\n",
       "      <th>obj</th>\n",
       "      <th>parameters</th>\n",
       "      <th>sentence</th>\n",
       "      <th>signature</th>\n",
       "      <th>simple_class_name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>valueOf</td>\n",
       "      <td>java.sql.Date</td>\n",
       "      <td>IllegalArgumentException</td>\n",
       "      <td>[s]</td>\n",
       "      <td>if the date given is not in the JDBC date esca...</td>\n",
       "      <td>public static Date valueOf(String s)</td>\n",
       "      <td>Date</td>\n",
       "      <td>exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>valueOf</td>\n",
       "      <td>java.sql.Date</td>\n",
       "      <td>NullPointerException</td>\n",
       "      <td>[date]</td>\n",
       "      <td>if date is null</td>\n",
       "      <td>public static Date valueOf(LocalDate date)</td>\n",
       "      <td>Date</td>\n",
       "      <td>exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>before</td>\n",
       "      <td>java.util.Date</td>\n",
       "      <td>NullPointerException</td>\n",
       "      <td>[when]</td>\n",
       "      <td>if when is null.</td>\n",
       "      <td>public boolean before(Date when)</td>\n",
       "      <td>Date</td>\n",
       "      <td>exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>after</td>\n",
       "      <td>java.util.Date</td>\n",
       "      <td>NullPointerException</td>\n",
       "      <td>[when]</td>\n",
       "      <td>if when is null.</td>\n",
       "      <td>public boolean after(Date when)</td>\n",
       "      <td>Date</td>\n",
       "      <td>exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>compareTo</td>\n",
       "      <td>java.util.Date</td>\n",
       "      <td>NullPointerException</td>\n",
       "      <td>[anotherDate]</td>\n",
       "      <td>if anotherDate is null.</td>\n",
       "      <td>public int compareTo(Date anotherDate)</td>\n",
       "      <td>Date</td>\n",
       "      <td>exception</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            api full_class_name                       obj     parameters  \\\n",
       "6484    valueOf   java.sql.Date  IllegalArgumentException            [s]   \n",
       "6485    valueOf   java.sql.Date      NullPointerException         [date]   \n",
       "8670     before  java.util.Date      NullPointerException         [when]   \n",
       "8671      after  java.util.Date      NullPointerException         [when]   \n",
       "8672  compareTo  java.util.Date      NullPointerException  [anotherDate]   \n",
       "\n",
       "                                               sentence  \\\n",
       "6484  if the date given is not in the JDBC date esca...   \n",
       "6485                                    if date is null   \n",
       "8670                                   if when is null.   \n",
       "8671                                   if when is null.   \n",
       "8672                            if anotherDate is null.   \n",
       "\n",
       "                                       signature simple_class_name       type  \n",
       "6484        public static Date valueOf(String s)              Date  exception  \n",
       "6485  public static Date valueOf(LocalDate date)              Date  exception  \n",
       "8670            public boolean before(Date when)              Date  exception  \n",
       "8671             public boolean after(Date when)              Date  exception  \n",
       "8672      public int compareTo(Date anotherDate)              Date  exception  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exception_caveat_df[exception_caveat_df['simple_class_name'] == \"Date\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4101\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in exception_caveat_df.index:\n",
    "    obj = exception_caveat_df.iloc[i]\n",
    "    rules = get_range_rules(obj)\n",
    "    if rules:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SignedInfo', 'si'],\n",
       " ['KeyInfo', 'ki'],\n",
       " ['List', 'objects'],\n",
       " ['String', 'id'],\n",
       " ['String', 'signatureValueId']]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_params(signature):\n",
    "    signature = re.sub(r'.*\\b(public|private|protected)\\b', '', signature)\n",
    "    params = re.search(r'\\(([^\\)]*)\\)', signature)\n",
    "    if params:\n",
    "        params = params.group(1)\n",
    "        params = params.split(', ')\n",
    "        params = map(lambda x: re.sub(r'<[^>]*>', '', x), params)\n",
    "        return [x.split() for x in params]\n",
    "    \n",
    "def get_single_param_index(params, param):\n",
    "    l = [x[1] for x in params]\n",
    "    for i, e in enumerate(l):\n",
    "        if e == param:\n",
    "            return i\n",
    "    \n",
    "def get_param_indices(params, rules):\n",
    "    l = [x[1] for x in params]\n",
    "    indices = []\n",
    "    for i, e in enumerate(l):\n",
    "        if e in rules:\n",
    "            indices.append(i)\n",
    "            \n",
    "    return indices\n",
    "    \n",
    "get_params('public abstract XMLSignature newXMLSignature(SignedInfo si, KeyInfo ki, List<? extends XMLObject> objects, String id, String signatureValueId)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all non-null exceptions caveats\n",
    "with open('./output/non_null_rules.json', 'w+') as f:\n",
    "    d = {}\n",
    "    \n",
    "    for i in exception_caveat_df.index:\n",
    "        obj = exception_caveat_df.iloc[i]\n",
    "        rules = get_not_null_exception_rules(obj)\n",
    "        if rules:\n",
    "            params = get_params(obj['signature'])\n",
    "            types = [x[0] for x in params]\n",
    "            \n",
    "            indices = get_param_indices(params, rules)\n",
    "            if indices:\n",
    "                res = {\n",
    "                    'className': obj['full_class_name'], \n",
    "                    'api': obj['api'], \n",
    "                    'signature': obj['signature'],\n",
    "                    'paramTypes': types,\n",
    "                    'notNullIndices': indices\n",
    "                }         \n",
    "                d[i] = res            \n",
    "                \n",
    "    for i in parameter_caveat_df.index:\n",
    "        obj = parameter_caveat_df.iloc[i]\n",
    "        rules = is_not_null_parameter_caveat(obj)\n",
    "        if rules:\n",
    "            params = get_params(obj['signature'])\n",
    "            types = [x[0] for x in params]\n",
    "            index = get_param_indices(params, [rules])\n",
    "            \n",
    "            if index:\n",
    "                if i in d:\n",
    "                    c += 1\n",
    "                    d[i]['notNullIndices'].append(index)\n",
    "                else:\n",
    "                    res = {\n",
    "                        'className': obj['full_class_name'], \n",
    "                        'api': obj['api'], \n",
    "                        'signature': obj['signature'],\n",
    "                        'paramTypes': types,\n",
    "                        'notNullIndices': [index]\n",
    "                    }\n",
    "                    d[i] = res\n",
    "    \n",
    "    ujson.dump([d[i] for i in d], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4119\n"
     ]
    }
   ],
   "source": [
    "# write all exception range rules\n",
    "with open('./output/exception_range_rules.json', 'w+') as f:\n",
    "    res = []\n",
    "    c = 0\n",
    "    for i in exception_caveat_df.index:\n",
    "        obj = exception_caveat_df.iloc[i]\n",
    "        rules = get_range_rules(obj)\n",
    "        \n",
    "        # skip all constraints with and conditions\n",
    "        if ' and ' in obj['sentence']:\n",
    "            continue\n",
    "        \n",
    "        if rules:\n",
    "            params = get_params(obj['signature'])\n",
    "            types = [x[0] for x in params]\n",
    "            \n",
    "            s = set()\n",
    "            valid_rules = []\n",
    "            for rule in rules:\n",
    "                if 'param' in rule and 'op' in rule and 'constraint' in rule:\n",
    "                    rule['param'] = get_single_param_index(params, rule['param'])\n",
    "                    valid_rules.append(rule)\n",
    "            \n",
    "            if valid_rules:\n",
    "                res.append({\n",
    "                    'className': obj['full_class_name'], \n",
    "                    'api': obj['api'], \n",
    "                    'signature': obj['signature'],\n",
    "                    'paramTypes': types,\n",
    "                    'rangeRules': valid_rules\n",
    "                })\n",
    "            c += 1\n",
    "            \n",
    "    ujson.dump(res, f)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230\n",
      "3464\n"
     ]
    }
   ],
   "source": [
    "with open('./output/exception_range_rules.json') as f, open('./output/exception_range_rules_filtered.json', 'w+') as f_out:\n",
    "    arr = ujson.load(f)\n",
    "    filtered = []\n",
    "    c, n = 0, 0\n",
    "    for e in arr: \n",
    "        filtered_rules = []\n",
    "        for rule in e['rangeRules']:\n",
    "            try:\n",
    "                if rule['constraint'] == 'null':\n",
    "                    n += 1\n",
    "                else:\n",
    "                    int(rule['constraint'])\n",
    "                    c += 1\n",
    "                filtered_rules.append(rule)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "        if filtered_rules:\n",
    "            e['rangeRules'] = filtered_rules\n",
    "            filtered.append(e)\n",
    "    print(c)\n",
    "    print(n)\n",
    "    ujson.dump(filtered, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api                                                   getOverrideStyle\n",
      "full_class_name                            org.w3c.dom.css.DocumentCSS\n",
      "obj                                                                elt\n",
      "parameters                                            [elt, pseudoElt]\n",
      "sentence                                This parameter cannot be null.\n",
      "signature            CSSStyleDeclaration getOverrideStyle(Element e...\n",
      "simple_class_name                                          DocumentCSS\n",
      "type                                                         parameter\n",
      "Name: 7587, dtype: object\n"
     ]
    }
   ],
   "source": [
    "is_not_null_parameter_caveat(parameter_caveat_df.iloc[7587])\n",
    "print(parameter_caveat_df.iloc[7587])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
