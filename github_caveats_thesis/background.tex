\chapter{Related Work}
\label{cha:background}
This chapter provides an overview of the background for API caveats, linking API caveats to code examples with NLP techniques, and the use of static code analysis to detect API errors or misuses. \\
The term \textit{API reference documentation} or \textit{API documentation} is adopted throughout this thesis to refer to the set of \textit{documents} that are indexed by an \textit{API element} such as a class or method (\cite{maalej2013patterns}). For example, the Java 12 reference documentation consists of documents as web-pages with each describing a specific Java class (\lstinline{String}, \lstinline{ArrayList} etc.). \\

Section \ref{sec:related-api-caveats} references the papers that termed \textit{API caveats} and extended upon this concept for linkage of API caveats to code.\\

Section \ref{sec:related-nlp} mentions related works that have applied NLP techniques to the domain of API documentation.\\

Section \ref{sec:related-static-code-analysis} references related works that applied static code analysis to the domain of API documentation.\\

\section{API Caveats}
\label{sec:related-api-caveats}
API reference documentation consists of a taxonomy of knowledge types that are defined by \cite{maalej2013patterns}. A particular knowledge type identified as \textit{directives} ``specifies what users are allowed/not allowed to do with the API element''. This is identified as a notable component of API reference documentation by \cite{caveat-knowledge-graph} that includes all forms of constraints and is therefore referred to as \textit{API caveats}. These constraints are of particular interest as they can be used to determine how accessible an API document is. Specifically, accessibility of documentation is an essential part of any API/framework because it is used to describe functionality and usage of the associated API. \citeauthor{caveat-knowledge-graph} conducted a formative study of the Q\&A website Stack Overflow to highlight the prevalence of issues involving API caveats for programmers. Also, a set of syntactic patterns were identified that could be used to recognise API caveats (see Table \ref{tab:caveat-keywords}). Moreover, API caveats have many practical applications such as the examination of the quality/validity of Stack Overflow answers \cite{xiaoxue}, construction of a knowledge graph for information retrieval purposes or entity-centric searches of API caveats \cite{construct-knowledge-graph}, and augmentation of caveats with code examples \cite{jiamou}. In particular, the work by \cite{jiamou} is the foundations for Chapter \ref{cha:infoRetrieval}. It was shown that one possible solution for linking caveats to code is by indirectly using community text from Q\&A websites. This approach used the NLP techniques of mainly word2vec sentence embedding to the sentences of API caveats and answer posts on Stack Overflow. The cosine similarity of these vector outputs could then be used to determine the relatedness of these vectors, which represents sentence similarity. The code examples from the answer and question posts could then be inferred as ``good'' and ``bad'' code examples respectively for the given API caveat. 

\section{Natural Language Processing for API Documents}
\label{sec:related-nlp}
Other NLP-centered works for linking API documentation to code have also been proposed. For example, CROKAGE (Crowd Knowledge Answer Generator) is a tool that takes a query input and returns programming solutions consisting of both code and explanations. This is achieved with several NLP models and word embedding approaches including Lucene Index, FastText, IDF and an API inverted index. For relevance scoring, CROKAGE also utilises the BM25 function and TF-IDF. Note that only BM25 and TF-IDF are explained in further detail in Chapter \ref{cha:infoRetrieval} (Section \ref{sec:info-design}). An explanation of the other methods will not be presented here as they are not used. Besides this, another solution proposed is called BIKER (Bi-Information source-based KnowledgE Recommendation), which focuses on helping developers find APIs appropriate for their programming tasks \cite{huang2018api}. BIKER uses a combination of language models involving IDF and word2vec, and similar to the other works mentioned retrieves relevant posts from Stack Overflow via similarity functions for a given query. The advantage of deep learning with word2vec has also been investigated by \cite{van2017combining}. This involved representing code in a higher-dimensional space (i.e. vectors). \\
In terms of parsing semi-structured natural language, \cite{pandita2012inferring} proposes an approach using part-of-speech tagging, and phrase and clause parsing to identify sentences that describe code contracts via first-order logic (FOL) expressions with precision and recall of 91.8\% and 93\% respectively. Similarly, Jdoctor is proposed by \cite{blasi2018translating}, which uses sentence normalisation techniques to translate Javadoc comments to executable Java expressions. This tool generates procedure specifications that are analogous to caveat contracts but differ in representation.  The caveat contracts in Chapter \ref{cha:codeAnalysis} are kept in an abstract form that is only resolved to Java expressions by a checker program (IntelliJ plugin). Overall, Jdoctor boasts an overall precision and recall of 92\% and 83\% respectively, which we note is a baseline objective for this thesis.

\section{Code Analysis Applications with API Documents}
\label{sec:related-static-code-analysis}
A code-analysis centered solution for linkage of API documents and code was proposed by \cite{live-api-doc}. This uses deductive linking, a process where the abstract syntax tree (AST) of a code snippet from online websites is analysed. The relevant API elements are then detected and linked to associated API documents. Another approach combines NLP and code analysis to detect errors such as obsolete code samples \cite{zhong2013detecting}. For this, the names of API elements from code samples are compared to the set of all existing API elements. Mismatches in API element names are then be reported as documentation errors. Another interesting approach for detecting API misuse ignores API documentation and data-mines correct code usage using a large set of code samples on GitHub \cite{code-examples}. This is achieved by traversing ASTs and generating API call sequences, representations of API calls and their context. Correct usage patterns are then applied to Stack Overflow to determine how reliable code examples are on Q\&A websites. Besides this, \cite{zhou-directive} provides a method of detecting defects between API documents and their code implementations by extracting the constraints from directives and code as FOL expressions. These expressions are then resolved with a Satisfiability Modulo Theories (SMT) solver. In particular, several categories of constraints for directives, which represent the largest portion of API documentation (43.7\%) \cite{monperrus2012should}, are identified. To reduce the scope of mapping API caveats to code, the heuristic patterns and regular expressions from this work are therefore used as the building blocks for the construction of caveat contracts in Chapter \ref{cha:codeAnalysis}.
The concept of mutation analysis has also been suggested for exposing API misuse by \cite{mutation-analysis}. Another approach involves mutation analysis, which consists of small modifications to a program that are then executed with a given test suite. Execution data from the stack trace of these programs can then be used to determine whether what constitutes an API misuse. For an example of the applications of static code analysis,  \cite{bae2014safewapi} proposes an error detection method for JavaScript web applications. Note that JavaScript is a dynamically typed programming language while Java, the main focus of this thesis is statically typed. It was shown that static type analysis can also be used for dynamically typed languages after slight modifications. Overall, the method proposed uses the fact that Web APIs are typically specified in a certain format known as Interface Definition Language, which exposes function semantics.

\section{Summary}
This chapter provides an overview of the related works for API caveats, NLP applied to API documentation and static code analysis for API misuse detection. In particular, key background information for Chapters \ref{cha:infoRetrieval} and \ref{cha:codeAnalysis} is provided, and some terminology used is defined to avoid ambiguity for readers. In Chapter \ref{cha:infoRetrieval}, the techniques in \cite{jiamou} are applied to GitHub data to investigate linking API caveats to a different community platform domain (GitHub).


